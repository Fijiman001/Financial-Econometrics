# -*- coding: utf-8 -*-
"""FE_project_Nour

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r8iJ-kfPXh-Icjiltsltv1iVSZISgial
"""

from google.colab import drive

drive.mount('/content/drive/', force_remount=True)
# !ls "/content/drive/MyDrive/FE_projects/"
# !ls "/content/drive/Shared Drives/FE_projects/"

"""The data is from FRED-MD:
https://fg-research.com/blog/general/posts/fred-md-overview.html

Follow the links on the page to get to the page with the data:
https://www.stlouisfed.org/research/economists/mccracken/fred-databases
"""

import pandas as pd
import numpy as np
df = pd.read_csv('/content/drive/MyDrive/FE_projects/2025-03.csv')

#df = pd.read_csv('/content/drive/MyDrive/FE_projects/2003-12.csv')
#df = pd.read_csv('/content/drive/MyDrive/FE_projects/FRED-MD_2015m5.csv')
#df = pd.read_csv("FRED-MD_2015m5.csv")
#df = pd.read_csv('FE_projects/2025-03.csv')
#df

"""ALSO: Instead of manually testing the series, we can follow the authors' FREDMD's recommendation of how to best make the time series stationary:
![image.png](data:image/png;base64,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)
"""

import os
import pandas as pd
import numpy as np

# define function to transform data according to recommendations
def transform_series(x, tcode):
    if tcode == 1:
        return x
    elif tcode == 2:
        return x.diff()
    elif tcode == 3:
        return x.diff().diff()
    elif tcode == 4:
        return np.log(x)
    elif tcode == 5:
        return np.log(x).diff()
    elif tcode == 6:
        return np.log(x).diff().diff()
    elif tcode == 7:
        return x.pct_change()
    else:
        raise ValueError(f"unknown `tcode` {tcode}")

# define function to remove outliers beyond a threshold
# here: values beyond 3 standard deviations are considered outliers
def remove_outliers(series, threshold=3.0):
    # compute mean and std, skip NaNs
    mean = series.mean()
    std = series.std()
    # mask values where deviation exceeds threshold
    return series.mask((series - mean).abs() > threshold * std)

# define function to apply to different time series
def get_data(filename, transform=True, outlier_threshold=3.0):
    '''
    Define and transform the time series, and optionally remove outliers.

    Parameters
    ----------
    filename : str
        Path to the CSV file containing data and transformation codes.
    transform : bool, optional
        Whether to apply transformations (default True).
    outlier_threshold : float, optional
        Number of standard deviations to use when masking outliers (default 3.0).
    '''

    # load the data, skipping the second row which contains transformation codes
    data = pd.read_csv(filename, skiprows=[1], index_col=0)
    data.columns = [c.upper() for c in data.columns]

    # process the dates
    data = data.loc[pd.notna(data.index), :]
    data.index = pd.date_range(start="1959-01-01", freq="MS", periods=len(data))

    if transform:
        # read transformation codes from the first row
        tcodes = pd.read_csv(filename, nrows=1, index_col=0)
        tcodes.columns = [c.upper() for c in tcodes.columns]

        # apply transformation per series
        data = data.apply(lambda x: transform_series(x, tcodes[x.name].item()))

    # remove outliers if threshold is specified
    if outlier_threshold is not None:
        data = data.apply(lambda x: remove_outliers(x, threshold=outlier_threshold))

    return data

"""# Using Most Recent Data"""

# Remove the first -- second in data frame -- row (which held the tcodes)
# df = get_data("FE_projects/2025-03.csv",transform=True)
df = get_data('/content/drive/MyDrive/FE_projects/2025-03.csv',transform=True)
#df = get_data('2025-03.csv',transform=True)

# make 1960:3 the start to 2014:12
df=df.iloc[12:-2,:]
df

"""# Brief Data Description for Report

Source: FRED-MD: Monthly Data.

FRED-MD is a large macroeconomic database of 134 -- actually only 127 -- monthly U.S.
indicators. It mimicks the coverage of datasets already used in the literature -- e.g. Stock and Watson (2002) but they add three appealing features: They are updated in real-time through the FRED database. They are publicly accessible, facilitating the replication of empirical work. And they relieve the researcher of the task of incorporating data changes and revisions (a task accomplished by the Data Desk at the Federal Reserve Bank of St. Louis.

The FRED-MD dataset includes eight different categories of macroeconomic indicators (see the Appendix for the full list):

Output and Income

Labor Market

Consumption and Orders

Orders and Inventories

Money and Credit

Interest Rates and Exchange Rates

Prices

Stock Market

######


Threats to reproducability:

"The main difficulty is almost entirely due
to changing definitions and data availability. Even with careful selection of variables that meet the
fourth criterion of Stock and Watson (1996), researchers have often had to deal with data revisions
that took place for one reason or another."

Summary of adjustements can be found in the description paper of FRED-MD, page 5.

######

Notes on the paper and the original vs. used data:

Not outlier adjustments have been made to the raw data.

Volatility in Ludvigson and Ng was realized volatility. BIC was used for PCA Analysis.

All of the raw data in xt are standardized prior to estimation.




"""

# df.columns
df.describe()

"""# SKIP UNTIL PCA Paper Recreation - FRED-MD: A Monthly Database for Macroeconomic Research

## Balanced Panel

See: https://fg-research.com/blog/general/posts/fred-md-overview.html
"""

# Remove the first row (which held the tcodes)
df = get_data("/content/drive/MyDrive/FE_projects/FRED-MD_2015m5.csv",transform=True)
df

"""we actually need to drop the last row, the authors have 675 observations not 676.

Following previous studies, we take 1960:1 as the start of the sample. After losing two observations to data transformation, the panel we use for analysis is for the sample 1960:3 to 2014:12 with 658 observations
"""

# make 1960:3 the start to 2014:12
df=df.iloc[14:-4,:]
df

# We Double check the amount of missing observations at the beginning and the end of the sample
sum(df.isna().sum())

# output: 852

# if df.isna().sum() > 0 has a true entry, drop the respective column
df = df.dropna(axis=1)
print(sum(df.isna().sum()))

# output: 0
# We have our balanced panel without missing values
df.head()

"""we get the exact same dataframe

## Non-Balanced Panel Data for Paper Results
We do not drop the other series and use our EM algorithm instead to fill missing observations
"""

# Remove the first row (which held the tcodes)
df = get_data("/content/drive/MyDrive/FE_projects/FRED-MD_2015m5.csv",transform=True)
# male 1960:3 the start to 2014:12
df=df.iloc[12:-1,:]
df

"""## SKIPFurther Analysis

While we provide a csv file with current and historical data, FRED-MD is not a balanced panel
for a number of reasons:

(1) The S&P PE ratio (series 83) is taken from Shiller’s website and is released with roughly a
6-month lag. Hence observations are missing at the end of the sample.

(2) The Michigan Survey of Consumer Sentiment (series 130) is available only quarterly prior to
1977:11, and recent data are available in FRED with a 1-year lag.

(3) The trade-weighted exchange rate (series 101) is available in FRED only through 1973:1, and
we have not found other documented sources with which to splice the series.

(4) Seasonally adjusted housing permits (series 55-59) exist only through 1960:01.

(5) A few Value of Manufacturers’ Orders components such as Nondefense Capital Goods (series
66) and especially Consumer Goods (series 64) have a limited history because of the new
NAICS discussed above.
"""

tickers = [
    # Group 1: Output and Income
    'RPI', 'W875RX1', 'INDPRO', 'IPFPNSS', 'IPFINAL', 'IPCONGD', 'IPDCONGD',
    'IPNCONGD', 'IPBUSEQ', 'IPMAT', 'IPDMAT', 'IPNMAT', 'IPMANSICS', 'IPB51222s',
    'IPFUELS', 'NAPMPI', 'CUMFNS',

    # Group 2: Labor Market
    'HWI', 'HWIURATIO', 'CLF16OV', 'CE16OV', 'UNRATE', 'UEMPMEAN', 'UEMPLT5',
    'UEMP5TO14', 'UEMP15OV', 'UEMP15T26', 'UEMP27OV', 'CLAIMSx', 'PAYEMS',
    'USGOOD', 'CES1021000001', 'USCONS', 'MANEMP', 'DMANEMP', 'NDMANEMP',
    'SRVPRD', 'USTPU', 'USWTRADE', 'USTRADE', 'USFIRE', 'USGOVT', 'CES0600000007',
    'AWOTMAN', 'AWHMAN', 'NAPMEI', 'CES0600000008', 'CES2000000008',
    'CES3000000008',

    # Group 3: Consumption and Orders
    'HOUST', 'HOUSTNE', 'HOUSTMW', 'HOUSTS', 'HOUSTW', 'PERMIT', 'PERMITNE',
    'PERMITMW', 'PERMITS', 'PERMITW',

    # Group 4: Orders and Inventories
    'DPCERA3M086SBEA', 'CMRMTSPLx', 'RETAILx', 'NAPM', 'NAPMNOI', 'NAPMSDI',
    'NAPMII', 'ACOGNO', 'AMDMNOx', 'ANDENOx', 'AMDMUOx', 'BUSINVx', 'ISRATIOx',
    'UMCSENTx',

    # Group 5: Money and Credit
    'M1SL', 'M2SL', 'M2REAL', 'AMBSL', 'TOTRESNS', 'NONBORRES', 'BUSLOANS',
    'REALLN', 'NONREVSL', 'CONSPI', 'MZMSL', 'DTCOLNVHFNM', 'DTCTHFNM',
    'INVEST',

    # Group 6: Interest Rate and Exchange Rates
    'FEDFUNDS', 'CP3Mx', 'TB3MS', 'TB6MS', 'GS1', 'GS5', 'GS10', 'AAA', 'BAA',
    'COMPAPFFx', 'TB3SMFFM', 'TB6SMFFM', 'T1YFFM', 'T5YFFM', 'T10YFFM',
    'AAAFFM', 'BAAFFM', 'TWEXMMTH', 'EXSZUSx', 'EXJPUSx', 'EXUSUKx', 'EXCAUSx',

    # Group 7: Prices
    'PPIFGS', 'PPIFCG', 'PPIITM', 'PPICRM', 'OILPRICEx', 'PPICMM', 'NAPMPRI',
    'CPIAUCSL', 'CPIAPPSL', 'CPITRNSL', 'CPIMEDSL', 'CUSR0000SAC', 'CUUR0000SAD',
    'CUSR0000SAS', 'CPIULFSL', 'CUUR0000SA0L2', 'CUSR0000SA0L5', 'PCEPI',
    'DDURRG3M086SBEA', 'DNDGRG3M086SBEA', 'DSERRG3M086SBEA',

    # Group 8: Stock Market
    'S&P 500', 'S&P: indust', 'S&P div yield', 'S&P PE ratio'
]

# df = df.iloc[13:-254,:] # to check for the Stock and Watson data
df = df.iloc[15:,1:] # to check for the Stock and Watson data

# # drop from tickers entries that are not in df
#tickers_in_df = [col for col in tickers if col in df.columns] # create new list with only valid tickers

# # drop from df columns that are not in tickets
#df = df.loc[:,tickers_in_df]
df

from statsmodels.tsa.stattools import adfuller

def perform_adf_test(series):
    result = adfuller(series)
    return result[0], result[1]  # Return ADF statistic and p-value

adf_results = {}
for col in df.columns:
    try:
        adf_statistic, p_value = perform_adf_test(df[col].dropna())
        adf_results[col] = {'ADF Statistic': adf_statistic, 'p-value': p_value}
    except Exception as e:
      print(f"Error processing column {col}: {e}")
      adf_results[col] = {'ADF Statistic': None, 'p-value': None}

adf_results_df = pd.DataFrame.from_dict(adf_results, orient='index')
adf_results_df

adf_results_df.loc['USGOVT']

non_stationary_data = adf_results_df[adf_results_df['p-value']>0.5].index.tolist()
df[non_stationary_data] = np.log(df[non_stationary_data]).diff()
df = df.iloc[:,1:]

# second time
adf_results = {}
for col in df.columns:
    try:
        adf_statistic, p_value = perform_adf_test(df[col].dropna())
        adf_results[col] = {'ADF Statistic': adf_statistic, 'p-value': p_value}
    except Exception as e:
      print(f"Error processing column {col}: {e}")
      adf_results[col] = {'ADF Statistic': None, 'p-value': None}

adf_results_df = pd.DataFrame.from_dict(adf_results, orient='index')
non_stationary_data = adf_results_df[adf_results_df['p-value']>0.05].index.tolist()
non_stationary_data

df[non_stationary_data] = df[non_stationary_data].diff()
# df = df.iloc[13:,:]

# third time
adf_results = {}
for col in df.columns:
    try:
        adf_statistic, p_value = perform_adf_test(df[col].dropna())
        adf_results[col] = {'ADF Statistic': adf_statistic, 'p-value': p_value}
    except Exception as e:
      print(f"Error processing column {col}: {e}")
      adf_results[col] = {'ADF Statistic': None, 'p-value': None}

adf_results_df = pd.DataFrame.from_dict(adf_results, orient='index')
non_stationary_data = adf_results_df[adf_results_df['p-value']>0.05].index.tolist()

non_stationary_data

df[non_stationary_data] = df[non_stationary_data].diff()
# df = df.iloc[13:,:]

adf_statistic, p_value = perform_adf_test(df['USGOVT'].dropna())
adf_statistic, p_value

# Already done above
# df = df.iloc[15:,:]

import matplotlib.pyplot as plt

# Assuming 'df' is your DataFrame
for col in df.columns:
    plt.figure(figsize=(10, 6))  # Adjust figure size if needed
    plt.plot(df[col])
    plt.title(f'Plot of {col}')
    plt.xlabel('Index')
    plt.ylabel(col)
    plt.grid(True)
    plt.show()

"""data description and basic algorithm discusses in the Stock and Watson paper can be found at: https://s3.amazonaws.com/real.stlouisfed.org/wp/2015/2015-012.pdf

Criterion for choosing number of factors in factor models on page 7:
We want to have a sense of whether the number of factors is sensitive to the
vintage of data used. Hence, for our purpose, which criterion we use is not so important provided
that the same criterion is used throughout. We use the P Cp criteria developed in Bai and Ng
(2002), which is a generalization of Mallow’s Cp criteria for large dimensional panels

Alternatively, can check the largest eigenvalues or choose the number based on the best model fit.

-----------------------------------------------

There are, however, 22
series that have the idiosyncratic component explaining 90% of the variation. The ten series with the
largest idiosyncratic component are ’realln’,’busloans’,’claimsx’, ’cpiappsl’, ’ipfuels’, ’dtcolnvhfnm’,
’cuur0000sad’,’dtcthfnm’, ’ddurrg3m086sbea’, ’cpimedsl’, ’invest’. A case can be made to drop
these series from the panel; as discussed in Boivin and Ng (2006), noisy data can worsen the
quality of the factor estimates

----------------------------------------------

Alternatively, a balanced panel of 130 series dating from 1960:1 to 2014:12 can
be formed by dropping series 64, 66, 101, and 130
"""

# We manually overwrite and take F.D. of USGOVT even though uniit root presence was rejected.
# df['USGOVT'] = np.log(df['USGOVT']).diff()
# df['USGOVT']

from sklearn.decomposition import PCA

#@markdown First code (initialised with means for the missing values)
# def em_dynamic_pca(data, n_factors, max_iter=100, tol=1e-6):
#   """ Estimate dynamic factors via PCA using an EM algorithm to impute missing values.
#   Parameters:
#     data : pd.DataFrame or 2D numpy array
#         Data matrix with rows as time observations and columns as variables.
#         Missing values should be np.nan.
#     n_factors : int
#         The number of principal components (factors) to extract.
#     max_iter : int, optional (default=100)
#         Maximum number of iterations for the EM algorithm.
#     tol : float, optional (default=1e-6)
#         Convergence threshold based on the change in imputed missing values.

#   Returns:
#     factors : ndarray
#         The estimated factor time series (scores).
#     loadings : ndarray
#         The estimated loadings matrix.
#     X_filled : ndarray
#         The data matrix after imputation (in standardized scale).
#   """
#   # Convert input data to a numpy array if it is a DataFrame.
#   if isinstance(data, pd.DataFrame):
#       X = data.values.copy()
#   else:
#       X = np.array(data, copy=True)

#   # Store the indices of missing entries for use during the iterations.
#   missing_idx = np.isnan(X)

#   # Standardize the data: compute the mean and std using non-missing values.
#   means = np.nanmean(X, axis=0)
#   stds = np.nanstd(X, axis=0)

#   # Demean and standardize. (After this, non-missing entries have mean 0 and unit variance.)
#   X_standardized = (X - means) / stds

#   # Initialize missing entries with 0 (the unconditional mean on the standardized scale).
#   X_filled = X_standardized.copy()
#   X_filled[missing_idx] = 0.0

#   # Initialize variables for the EM algorithm
#   diff = np.inf
#   iter_count = 0

#   while diff > tol and iter_count < max_iter:
#       iter_count += 1

#       # --- E-step: factor extraction via PCA ---
#       pca = PCA(n_components=n_factors)
#       # The PCA works on the current filled data matrix
#       factors = pca.fit_transform(X_filled)   # shape: (n_samples, n_factors)
#       loadings = pca.components_.T              # shape: (n_variables, n_factors)

#       # --- M-step: reconstruct the data using the estimated factors ---
#       X_hat = np.dot(factors, loadings.T)   # reconstructed matrix in standardized units

#       # Compute change over missing entries to check for convergence.
#       # We compare only the imputed values as these are updated.
#       prev_imputed = X_filled[missing_idx]
#       new_imputed = X_hat[missing_idx]
#       diff = np.linalg.norm(new_imputed - prev_imputed)

#       # Update only the missing entries.
#       X_filled[missing_idx] = new_imputed

#       # Optionally, you can print the iteration progress.
#       # print(f"Iteration {iter_count}: diff = {diff:.6f}")

#   # (At this point, the algorithm has converged and X_filled holds the updated data in standardized units.)
#   # Factors and loadings are estimated from the last PCA run.

#   # If desired, you could transform the imputed data back to original scale:
#   X_reconstructed = X_filled * stds + means

#   return factors, loadings, X_filled, X_reconstructed

# # remove transformation row and date column for now
# df_subset = df.iloc[1:, 1:]

# # Set the number of factors according to your model specification
# n_factors = 8

# # Run the EM dynamic PCA routine
# factors, loadings, X_filled_std, X_filled_original = em_dynamic_pca(df_subset, n_factors)

# # Display the results.
# print("Estimated Factors (first 5 observations):")
# print(factors[:5])
# print("\nEstimated Loadings:")
# print(loadings)

"""change to conditional demeaning?

# PCA
"""

import numpy as np
import pandas as pd
from numpy.linalg import svd, norm
import warnings

def standardize_dataframe(df):
    """
    Standardizes the DataFrame by subtracting the mean and dividing by the standard
    deviation for each column. The mean and std are computed ignoring NaN values.

    Parameters:
      df : pandas DataFrame with time series data (rows are time, columns are variables)

    Returns:
      standardized_df : pandas DataFrame with standardized values
      stats_df        : DataFrame containing the mean and std for each column
    """
    # Calculate column-wise mean and standard deviation ignoring NaNs
    means = df.mean(skipna=True)
    stds = df.std(skipna=True)

    # Apply standardization: (x - mean) / std, preserving NaNs
    standardized_df = df.subtract(means).divide(stds)

    # Optionally, return the computed means and stds for later re-transformation if needed.
    stats_df = pd.DataFrame({'mean': means, 'std': stds})
    return standardized_df, stats_df

def initialize_balanced_panel(X):
    # Identify columns with no missing values
    balanced_cols = np.where(np.sum(np.isnan(X), axis=0) == 0)[0]
    if len(balanced_cols) == 0:
        warnings.warn("No fully balanced series found. Falling back to simple mean imputation.")
        return None, None
    X_balanced = X[:, balanced_cols]
    return X_balanced, balanced_cols

def em_dynamic_factor_balanced_init(df, num_factors, tol=1e-4, max_iter=100, return_estimated_X=False):
    """
    EM algorithm for dynamic factor analysis using initial estimates derived from a balanced panel.

    Parameters:
      df          : pandas DataFrame with shape (T, N); missing values should be np.nan.
      num_factors : integer, number of factors to extract.
      tol         : convergence tolerance.
      max_iter    : maximum number of iterations.

    Returns:
      F           : (T x num_factors) factor estimates (numpy array)
      Lambda      : (N x num_factors) loading estimates (numpy array)
      X_imputed   : Completed data matrix used in the final iteration.
    """
    # Convert DataFrame to numpy array (rows: time, columns: series)
    X = df.values.astype(float)  # shape: (T, N)
    T, N = X.shape

    # Create indicator matrix where 1 = observed, 0 = missing
    indicator = (~np.isnan(X)).astype(float)

    # --- Initialization using a balanced subset ---
    X_balanced, balanced_cols = initialize_balanced_panel(X)

    if X_balanced is not None:
        # Perform SVD/PCA on the balanced panel
        U_bal, s_bal, Vt_bal = svd(X_balanced, full_matrices=False)
        num_factors_init = np.min([num_factors, X_balanced.shape[1]])
        F_init = U_bal[:, :num_factors_init] * s_bal[:num_factors_init]  # (T x num_factors)
        Lambda_balanced = Vt_bal[:num_factors_init, :].T  # loadings for the balanced series (len(balanced_cols) x num_factors)

        # Estimate loadings for each series in the full dataset via OLS over available observations:
        Lambda_init = np.zeros((N, num_factors_init))
        for i in range(N):
            obs_idx = indicator[:, i].astype(bool)
            if np.sum(obs_idx) >= num_factors_init:  # Ensure enough observations
                F_obs = F_init[obs_idx, :]
                X_obs = X[obs_idx, i]
                # Solve the least squares problem F_obs * lambda_i = X_obs
                if np.linalg.matrix_rank(F_obs) == num_factors_init:
                    Lambda_init[i, :] = np.linalg.lstsq(F_obs, X_obs, rcond=None)[0]
                else:
                    Lambda_init[i, :] = 0
            else:
                Lambda_init[i, :] = 0

        # For missing entries, initialize using the product of the estimated loadings and factors.
        X_imputed = X.copy()
        for i in range(N):
            missing_idx = ~indicator[:, i].astype(bool)
            if np.any(missing_idx):
                # Impute as: X_hat = F_init * lambda_i
                X_imputed[missing_idx, i] = F_init[missing_idx, :].dot(Lambda_init[i, :])
    else:
        # Fall back to simple imputation if no balanced panel available.
        X_imputed = np.where(np.isnan(X), 0, X)
        Lambda_init = None
        F_init = None

    # --- EM algorithm iteration ---
    for it in range(max_iter):
        # M-step: Compute SVD on the imputed full data
        U, s, Vt = svd(X_imputed, full_matrices=False)
        F = U[:, :num_factors] * s[:num_factors]       # Factors (T x num_factors)
        Lambda = Vt[:num_factors, :].T                    # Loadings (N x num_factors)

        # Reconstruct the data matrix using the factor model.
        X_hat = F.dot(Lambda.T)

        # E-step: Update only the missing entries in the data matrix.
        X_new = X.copy()
        X_new[~indicator.astype(bool)] = X_hat[~indicator.astype(bool)]

        # Check convergence based on relative change of imputed values.
        if norm(X_new - X_imputed) / norm(X_imputed) < tol:
            print(f'Converged in {it+1} iterations.')
            X_imputed = X_new.copy()
            break

        X_imputed = X_new.copy()

    if return_estimated_X:
        return F, Lambda, X_imputed, X_hat
    else:
        return F, Lambda, X_imputed

# df_subset = df.iloc[:,1:].reset_index(drop=True)
# standardized_df, stats = standardize_dataframe(df_subset)
standardized_df, stats = standardize_dataframe(df)

num_factors = 3
F, Lambda, X_complete = em_dynamic_factor_balanced_init(standardized_df, num_factors)

import numpy as np
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.metrics import mean_squared_error

def compute_bic(X, n_components):
    """
    Computes the Bayesian Information Criterion (BIC) for a given number of components in PCA.

    Parameters:
    X (numpy array or pandas DataFrame): The data matrix (observations x features)
    n_components (int): Number of principal components to retain

    Returns:
    float: The BIC score for the chosen number of components
    """
    # Step 1: Perform PCA
    F, Lambda, X_complete, X_reconstructed = em_dynamic_factor_balanced_init(X, n_components, return_estimated_X=True)

    # Step 3: Calculate the residual sum of squares (RSS)
    rss = np.sum((X_complete - X_reconstructed) ** 2)

    # Step 4: Calculate the BIC
    n_samples, n_features = X_complete.shape
    n_parameters = n_components * n_features + n_components

    bic = n_samples * np.log(rss / n_samples) + n_parameters * (n_features+n_samples) * np.log(np.min([n_samples, n_features])) / (n_samples*n_features)
    return bic

def select_optimal_components(X, max_components=20):
    """
    Select the optimal number of PCA components based on the BIC criterion.

    Parameters:
    X (numpy array or pandas DataFrame): The data matrix (observations x features)
    max_components (int): Maximum number of components to test

    Returns:
    int: The optimal number of components based on BIC
    """
    bic_values = []

    for n_components in range(1, max_components + 1):
        bic = compute_bic(X, n_components)
        bic_values.append(bic)

    # Select the number of components that minimizes BIC
    optimal_components = np.argmin(bic_values) + 1  # +1 because we start from 1 component
    return optimal_components, bic_values


optimal_components, bic_values = select_optimal_components(standardized_df, max_components=10)

print(f"Optimal number of components: {optimal_components}")

X_complete.shape

bic_values

# removing the first transformation row significantly improve the graphs!
import matplotlib.pyplot as plt
plt.plot(F[:,0], label='factor 1')
plt.plot(F[:,1], label='factor 2')
plt.plot(F[:,2], label='factor 3')
plt.plot(F[:,3], label='factor 4')
plt.plot(F[:,4], label='factor 5')
plt.plot(F[:,5], label='factor 6')
plt.plot(F[:,6], label='factor 7')
plt.plot(F[:,7], label='factor 8')
plt.legend();

import statsmodels.api as sm

def compute_R2_values(X, factors):
  """ For each original variable (each column of X), run a regression on an increasing number of factors and store the R² value for each regression.
    Parameters:
    X       : numpy array (T x N), standardized data (each column is a series)
    factors : numpy array (T x r), estimated factor time series

  Returns:
    R2_matrix : numpy array (N x r), where each row i contains:
                [R2_i(1), R2_i(2), ..., R2_i(r)]
                with R2_i(k) = R² when series i is regressed on the first k factors.
  """
  T, N = X.shape
  r = factors.shape[1]
  R2_matrix = np.zeros((N, r))

  # Loop over each series (each variable i)
  for i in range(N):
      y = X[:, i]
      # For each increment k=1,..,r, run regression on the first k factors
      for k in range(1, r+1):
          X_k = factors[:, :k]
          X_k_const = sm.add_constant(X_k)
          model = sm.OLS(y, X_k_const).fit()
          R2_matrix[i, k-1] = model.rsquared
  return R2_matrix

def compute_incremental_R2(R2_matrix):
  """ Compute the incremental R² (mR2) for each series and then average across all series.
  For each series i, define:
    mR2_i(1) = R2_i(1)
    and for k >= 2,
    mR2_i(k) = R2_i(k) - R2_i(k-1)

  Also compute the average importance of factor-k over all series:
    mR2(k) = (1/N) * sum_{i=1}^{N} mR2_i(k)

  Parameters:
    R2_matrix : numpy array (N x r) with cumulative R² values

  Returns:
    mR2_individual: numpy array (N x r) of incremental R² for each series
    mR2_average   : numpy array (1 x r) of the average incremental R² for each factor
  """
  N, r = R2_matrix.shape
  mR2_individual = np.zeros((N, r))
  mR2_individual[:, 0] = R2_matrix[:, 0]

  for k in range(1, r):
      mR2_individual[:, k] = R2_matrix[:, k] - R2_matrix[:, k-1]

  mR2_average = np.mean(mR2_individual, axis=0)
  return mR2_individual, mR2_average

# Compute the cumulative R² for each series as factors are added.
R2_matrix = compute_R2_values(X_complete, F)

# Then compute the incremental R² (mR²) for each factor for each series and the average across series.
mR2_individual, mR2_average = compute_incremental_R2(R2_matrix)

series_names = df.columns.tolist()

# Optionally, create column labels for the factors
factor_labels = [f'Factor_{i+1}' for i in range(num_factors)]

# Create a DataFrame from the mR2_individual array with the desired indices and columns
mR2_df = pd.DataFrame(mR2_individual, index=series_names, columns=factor_labels)

mR2_df

""""Factor 1 explains 0.159 of the variation in
the data and can be interpreted as a real activity/employment factor since the mRi(1) associated with the industrial production and employment series are close to 0.7"
"""

mR2_df.sort_values(by='Factor_1', ascending=False).head(10)

mR2_df.sort_values(by='Factor_2', ascending=False).head(10)

mR2_df.sort_values(by='Factor_3', ascending=False).head(10)

mR2_df.sort_values(by='Factor_4', ascending=False).head(10)

mR2_df.sort_values(by='Factor_5', ascending=False).head(10)

mR2_df.sort_values(by='Factor_6', ascending=False).head(10)

mR2_df.sort_values(by='Factor_7', ascending=False).head(10)

mR2_df.sort_values(by='Factor_8', ascending=False).head(10)

mR2_average

sum(mR2_average)

"""Using the same transformations as the paper nearly gives us identical results, slight differences remain presumably due to NAs not being removed yet.

very close to R^2 of actually paper. The first factor explained 0.159 of the variation in the paper of the authors, by us 0.155. but our second factor is a bit off.

"Factor 2 contributes to 0.069
of the variation in the data and is dominated by forward-looking variables such as term interest rate spreads and inventories. Factor 3 has an mR2(3) of 0.066 and its explanatory power is concentrated on price variables and hence can be interpreted as an inflation factor. Factors 4 and 5 are a mix of housing and interest rate variables. Like Factor 1, Factor 6 concentrates on real/employment
variables. Factor 7 has explanatory power for stock market variables while factor 8 has explanatory power for exchange rates"

#### SKIP So, the previous code does not really give the same result, so let's just do a PCA on a balanced dataset
"""

import numpy as np
import pandas as pd
from numpy.linalg import svd

def pca_on_balanced_panel(df, num_factors=3):
    """
    Extracts the balanced panel (columns with no missing values) from df,
    standardizes the data, and performs PCA via SVD to extract factors and loadings.

    Parameters:
      df          : pandas DataFrame with shape (T, N) where each column is a variable.
      num_factors : integer specifying the number of factors to extract.

    Returns:
      factors     : numpy array of shape (T, num_factors) containing the factor estimates.
      loadings    : numpy array of shape (N_balanced, num_factors) containing the loading estimates.
      balanced_cols : list of column names representing the balanced panel.
    """
    # Identify the columns (series) with no missing observations.
    balanced_cols = [col for col in df.columns if df[col].notnull().all()]
    if len(balanced_cols) == 0:
        raise ValueError("No fully observed (balanced) columns were found in the dataset.")

    # Create a subset with the balanced panel.
    df_balanced = df[balanced_cols]

    # Standardize the data: for each variable subtract the mean and divide by standard deviation.
    df_balanced_std = (df_balanced - df_balanced.mean()) / df_balanced.std()

    # Convert the standardized data to a numpy array.
    # Note: rows = time observations, columns = balanced series.
    X = df_balanced_std.values  # shape: (T, N_balanced)

    # Run SVD to perform PCA.
    # X = U * s * Vt, where the columns of U are the left singular vectors.
    U, s, Vt = svd(X, full_matrices=False)

    # Compute the factor estimates as the first num_factors principal components.
    # Multiply U by the singular values s (for the selected factors) to obtain the factor scores.
    factors = U[:, :num_factors] * s[:num_factors]

    # The loadings are given by the rows of Vt.T corresponding to the first num_factors.
    loadings = Vt[:num_factors, :].T  # shape: (N_balanced, num_factors)

    return factors, loadings, balanced_cols

num_factors = 8  # Example: extracting three factors.
factors, loadings, balanced_cols = pca_on_balanced_panel(df, num_factors)

print("Shape of factor estimates (T x num_factors):", factors.shape)
print("Shape of loading estimates (N_balanced x num_factors):", loadings.shape)

plt.plot(F[:,0], label='factor 1')
plt.plot(F[:,1], label='factor 2')
plt.plot(F[:,2], label='factor 3')
plt.plot(F[:,3], label='factor 4')
plt.plot(F[:,4], label='factor 5')
plt.plot(F[:,5], label='factor 6')
plt.plot(F[:,6], label='factor 7')
plt.plot(F[:,7], label='factor 8')
plt.legend();

balanced_cols = [col for col in df.columns if df[col].notnull().all()]
if len(balanced_cols) == 0:
    raise ValueError("No fully observed (balanced) columns were found in the dataset.")

# Create a subset with the balanced panel.
df_balanced = df[balanced_cols]

# Compute the cumulative R² for each series as factors are added.
R2_matrix = compute_R2_values(df_balanced.to_numpy(), factors)

# Then compute the incremental R² (mR²) for each factor for each series and the average across series.
mR2_individual, mR2_average = compute_incremental_R2(R2_matrix)

series_names = df_balanced.columns.tolist()

# Optionally, create column labels for the factors
factor_labels = [f'Factor_{i+1}' for i in range(num_factors)]

# Create a DataFrame from the mR2_individual array with the desired indices and columns
mR2_df = pd.DataFrame(mR2_individual, index=series_names, columns=factor_labels)

print(mR2_average)

"""It did not change a lot... idk what is the problem then

From the descriptive paper: Factor 1 explains 0.159 of the variation in
the data and can be interpreted as a real activity/employment factor since the mRi(1) associated
with the industrial production and employment series are close to 0.7. Factor 2 contributes to 0.069
of the variation in the data and is dominated by forward-looking variables such as term interest rate
spreads and inventories. Factor 3 has an mR2
(3) of 0.066 and its explanatory power is concentrated
on price variables and hence can be interpreted as an inflation factor. Factors 4 and 5 are a mix
of housing and interest rate variables. Like Factor 1, Factor 6 concentrates on real/employment
variables. Factor 7 has explanatory power for stock market variables while factor 8 has explanatory
power for exchange rates.

# SKIP Regressions with above factors

# Regression with S&P 500 data?

We follow Ludvigson and Ng (2007) and aim to forecast excess returns and volatility, in this case for the S&P 500. Using the previously estimated factors
"""

# Checking Data availability of tickers:
# pip install yfinance pandas
import yfinance as yf
import pandas as pd
import numpy as np
import time

# 1) Define the tickers
SPX_TICKER  = "^GSPC"   # S&P 500 index
TBILL_TICKER = "^IRX"   # CBOE 13‑Week T‑Bill (^IRX gives the annualized % yield)
WMT_TICKER = "WMT"

tickers = [SPX_TICKER, TBILL_TICKER, WMT_TICKER]

print("Maximum price data history is:\n")
for ticker in tickers:
    price_history = yf.Ticker(ticker).history(period='max')
    print(f"{ticker} max price: {price_history['Close'].max()}")
    print("\nMinimum price data history is:\n")
    print(f"{ticker}: {price_history.index.min}")
    time.sleep(1)

# 2) Download history
#    Adjust start/end as needed
data = yf.download(
    [SPX_TICKER, TBILL_TICKER, WMT_TICKER],
    start="1973-01-01",
    end="2025-03-31",
    progress=False
)

# 3) Keep only the Adj Close columns
df_stocks = data["Close"].rename(columns={
    SPX_TICKER: "SPX_Close",
    WMT_TICKER: "WMT_Close",
    TBILL_TICKER: "Tbill_Yield"
})

# 4) Convert T‑bill from % to daily log‐yield
#    IRX is quoted as a percent annual rate, so:
df_stocks["Tbill_Yield"] = df_stocks["Tbill_Yield"] / 100            # → decimal annual rate
df_stocks["rf_daily"]    = np.log1p(df_stocks["Tbill_Yield"] / 252)   # assume 252 trading days

# 5) Compute daily SPX log‐return and excess‐return
df_stocks["spx_ret"]     = np.log(df_stocks["SPX_Close"]).diff()
df_stocks["spx_exret"]   = df_stocks["spx_ret"] - df_stocks["rf_daily"]
# same fore walmart WMT
df_stocks["wmt_ret"]     = np.log(df_stocks["WMT_Close"]).diff()
df_stocks["wmt_exret"]   = df_stocks["wmt_ret"] - df_stocks["rf_daily"]

# 6) Long Sample mean of daily excess return
Rbar = df_stocks["spx_exret"].mean()
Rbar_WMT = df_stocks["wmt_exret"].mean()

# 7) Squared Deviations will be the variance
df_stocks["sq_dev"] = (df_stocks["spx_exret"] - Rbar)**2
df_stocks["sq_dev_WMT"]= (df_stocks["wmt_exret"] - Rbar_WMT)**2

# 8) We aggregate to Monthly volatility from daily
# Sum daily numbers, then take the square-root
monthly_vol = (
    df_stocks["sq_dev"]
      .resample("ME")    # monthly groups instead of quarterly
      .sum()            # Σ (R_sk – R̄_s)^2 for k in month m
      .pipe(np.sqrt)    # √[ Σ (…) ]
      .rename("VOL")
)
monthly_vol_wmt = (
    df_stocks["sq_dev_WMT"]
      .resample("ME")    # monthly groups instead of quarterly
      .sum()            # Σ (R_sk – R̄_s)^2 for k in month m
      .pipe(np.sqrt)    # √[ Σ (…) ]
      .rename("VOL")
)

# 9) Monthly Panel
monthly = pd.DataFrame({
    "SPX_exret": df_stocks["spx_exret"].resample("ME").sum(),
    "WMT_exret": df_stocks["wmt_exret"].resample("ME").sum(),
    "Tbill_Yield": df_stocks["Tbill_Yield"].resample("ME").mean(),
    "VOL": monthly_vol,
    "VOL_WMT": monthly_vol_wmt
})

# remove day from date
monthly.index = monthly.index.to_period('M')
monthly

"""Analysing APPL - only run the one above or this one below, not both as they overwrite each other"""

# 2) Download history
#    Adjust start/end as needed
data = yf.download(
    [TBILL_TICKER, "AAPL"],
    start="1981-01-01",
    end="2025-03-31",
    progress=False
)

# 3) Keep only the Adj Close columns
df_stocks = data["Close"].rename(columns={
    "AAPL": "AAPL_Close",
    TBILL_TICKER: "Tbill_Yield"
})

# 4) Convert T‑bill from % to daily log‐yield
#    IRX is quoted as a percent annual rate, so:
df_stocks["Tbill_Yield"] = df_stocks["Tbill_Yield"] / 100            # → decimal annual rate
df_stocks["rf_daily"]    = np.log1p(df_stocks["Tbill_Yield"] / 252)   # assume 252 trading days

# 5) Compute daily SPX log‐return and excess‐return
# same fore walmart WMT
df_stocks["aapl_ret"]     = np.log(df_stocks["AAPL_Close"]).diff()
df_stocks["aapl_exret"]   = df_stocks["aapl_ret"] - df_stocks["rf_daily"]

# 6) Long Sample mean of daily excess return
Rbar_aapl = df_stocks["aapl_exret"].mean()

# 7) Squared Deviations will be the variance
df_stocks["sq_dev_aapl"]= (df_stocks["aapl_exret"] - Rbar_aapl)**2

# 8) We aggregate to Monthly volatility from daily
# Sum daily numbers, then take the square-root
monthly_vol_aapl = (
    df_stocks["sq_dev_aapl"]
      .resample("ME")    # monthly groups instead of quarterly
      .sum()            # Σ (R_sk – R̄_s)^2 for k in month m
      .pipe(np.sqrt)    # √[ Σ (…) ]
      .rename("VOL")
)

# 9) Monthly Panel
monthly = pd.DataFrame({
    "AAPL_exret": df_stocks["aapl_exret"].resample("ME").sum(),
    "Tbill_Yield": df_stocks["Tbill_Yield"].resample("ME").mean(),
    "VOL_AAPL": monthly_vol_aapl
})

# remove day from date
monthly.index = monthly.index.to_period('M')
monthly

"""we merge our dataframes"""

factors_df = pd.DataFrame(F, columns=[f"Factor_{i+1}" for i in range(8)])
factors_df.index = df.index
factors_df.index = factors_df.index.to_period('M')
factors_df

# Concatenate the factors DataFrame with the original DataFrame
# Reset the index of the original DataFrame to align with the factors
# df_merged = pd.concat([monthly, factors_df], axis=1)
# df_merged = df_merged.dropna(subset=['Factor_1', 'SPX_exret'])
# df_merged

"""## OLD SKIP to SOLUTION: Simple Regression

## 1 step ahead forecast
- To Do: do not only compare to AR(1) & factor with 1 lag, test more lags and different specifications
- In Ludvigson & Ng (2007):

**Overall** - taking monthly data, we see worse performance of the factor model compared to just a simple AR(1). In ludvigson and Ng (2007) quarterly data is used with quarterly forecasting, perhaps doing that would also show better factor model performance?
"""

import numpy as np
import pandas as pd
import statsmodels.api as sm
import matplotlib.pyplot as plt

def forecast_analysis(df_merged, ret_var, vol_var, factor_cols, h):
    # 1) Prepare leads and lags
    df = df_merged.copy()
    df["ret_lead"] = df[ret_var].shift(-h)
    df["vol_lead"] = df[vol_var].shift(-h)
    df["ret_t"]   = df[ret_var]
    df["vol_t"]   = df[vol_var]

    # 2) Drop missing
    df_ret = df[["ret_lead","ret_t"] + factor_cols].dropna()
    df_vol = df[["vol_lead","vol_t","Factor_1"]].dropna()

    # 3) Train/Test split (80/20)
    n_ret = len(df_ret)
    n_vol = len(df_vol)
    split_ret = int(0.8 * n_ret)
    split_vol = int(0.8 * n_vol)

    train_ret = df_ret.iloc[:split_ret]
    test_ret  = df_ret.iloc[split_ret:]
    train_vol = df_vol.iloc[:split_vol]
    test_vol  = df_vol.iloc[split_vol:]

    # 4) RETURN FORECASTS

    # 4a) Factor‐Augmented Model: ret_lead ~ const + ret_t + Factor_1…Factor_8
    X_tr_fac    = sm.add_constant(train_ret[["ret_t"] + factor_cols])
    X_te_fac    = sm.add_constant(test_ret[["ret_t"] + factor_cols])
    y_tr_ret    = train_ret["ret_lead"]
    y_te_ret    = test_ret["ret_lead"]
    fac_mod     = sm.OLS(y_tr_ret, X_tr_fac).fit()
    y_hat_fac   = fac_mod.predict(X_te_fac)
    resid_fac   = y_te_ret - y_hat_fac
    rmse_fac    = np.sqrt((resid_fac**2).mean())
    llf_fac     = fac_mod.llf

    # 4b) AR(1) Benchmark: ret_lead ~ const + ret_t
    X_tr_ar1  = sm.add_constant(train_ret[["ret_t"]])
    X_te_ar1  = sm.add_constant(test_ret[["ret_t"]])
    ar1_mod   = sm.OLS(y_tr_ret, X_tr_ar1).fit()
    y_hat_ar1 = ar1_mod.predict(X_te_ar1)
    resid_ar1 = y_te_ret - y_hat_ar1
    rmse_ar1  = np.sqrt((resid_ar1**2).mean())
    llf_ar1   = ar1_mod.llf

    # Print diagnostics
    print(f"Return Factor Model: RMSE={rmse_fac:.4f}, Log‐Lik={llf_fac:.2f}")
    print(f"Return AR(1) Model:   RMSE={rmse_ar1:.4f}, Log‐Lik={llf_ar1:.2f}")

    # 5) VOLATILITY FORECASTS

    # 5a) Factor‐Augmented Model: vol_lead ~ const + vol_t + Factor_1
    Xv_tr_fac  = sm.add_constant(train_vol[["vol_t","Factor_1"]])
    Xv_te_fac  = sm.add_constant(test_vol[["vol_t","Factor_1"]])
    yv_tr      = train_vol["vol_lead"]
    yv_te      = test_vol["vol_lead"]
    vfac_mod   = sm.OLS(yv_tr, Xv_tr_fac).fit()
    y_hat_vf   = vfac_mod.predict(Xv_te_fac)
    resid_vf   = yv_te - y_hat_vf
    rmse_vf    = np.sqrt((resid_vf**2).mean())
    llf_vf     = vfac_mod.llf

    # 5b) AR(1) Benchmark: vol_lead ~ const + vol_t
    Xv_tr_ar1  = sm.add_constant(train_vol[["vol_t"]])
    Xv_te_ar1  = sm.add_constant(test_vol[["vol_t"]])
    var1_mod   = sm.OLS(yv_tr, Xv_tr_ar1).fit()
    y_hat_v1   = var1_mod.predict(Xv_te_ar1)
    resid_v1   = yv_te - y_hat_v1
    rmse_v1    = np.sqrt((resid_v1**2).mean())
    llf_v1     = var1_mod.llf

    print(f"Volatility Factor Model: RMSE={rmse_vf:.4f}, Log‐Lik={llf_vf:.2f}")
    print(f"Volatility AR(1) Model:   RMSE={rmse_v1:.4f}, Log‐Lik={llf_v1:.2f}")

    # 6) PLOTS

    # Return residuals
    plt.figure()
    plt.plot(resid_fac.index.to_timestamp(), resid_fac)
    plt.title("Return Residuals — Factor Model")
    plt.xlabel("Date"); plt.ylabel("Residual")
    plt.show()

    # Return forecasts vs actual
    plt.figure()
    plt.plot(y_te_ret.index.to_timestamp(), y_te_ret,    "o-", label="Actual")
    plt.plot(y_te_ret.index.to_timestamp(), y_hat_fac,   "x--", label="Factor")
    plt.plot(y_te_ret.index.to_timestamp(), y_hat_ar1,  "^--", label="AR(1)")
    plt.title(f"{h}‑Step Return Forecast vs Actual")
    plt.xlabel("Date"); plt.ylabel("Excess Return"); plt.legend()
    plt.show()

    # Volatility residuals
    plt.figure()
    plt.plot(resid_vf.index.to_timestamp(), resid_vf)
    plt.title("Volatility Residuals — Factor Model")
    plt.xlabel("Date"); plt.ylabel("Residual")
    plt.show()

    # Volatility forecasts vs actual
    plt.figure()
    plt.plot(yv_te.index.to_timestamp(), yv_te,    "o-", label="Actual")
    plt.plot(yv_te.index.to_timestamp(), y_hat_vf, "x--", label="Factor")
    plt.plot(yv_te.index.to_timestamp(), y_hat_v1, "^--", label="AR(1)")
    plt.title(f"{h}‑Step Volatility Forecast vs Actual")
    plt.xlabel("Date"); plt.ylabel("Realized Volatility"); plt.legend()
    plt.show()

    # 7) Risk‑Return Regression (Eq. 7 from Ludvigson & Ng)

    # Align predictions
    m_hat = y_hat_fac
    s_hat = y_hat_vf
    idx   = m_hat.index.intersection(s_hat.index)
    m_hat = pd.Series(m_hat.values, index=y_te_ret.index).loc[idx]
    s_hat = pd.Series(s_hat.values, index=yv_te.index).loc[idx]

    rr_df = pd.DataFrame({
        "m_hat":     m_hat,
        "m_hat_lag": m_hat.shift(1),
        "s_hat":     s_hat,
        "s_hat_lag": s_hat.shift(1)
    }).dropna()

    X_rr = sm.add_constant(rr_df[["s_hat","s_hat_lag","m_hat_lag"]])
    y_rr = rr_df["m_hat"]
    rr_mod = sm.OLS(y_rr, X_rr).fit() # fit
    hac_res = rr_mod.get_robustcov_results(cov_type='HAC', maxlags=12) #HAC errors
    # print("\nRisk‐Return Regression (h=1) Summary:\n")
    # print(rr_mod.summary())
    print("\nHAC Errors:\n")
    print(hac_res.summary())

# 1-Step Ahead Forecast, AR(1) & Factor Models
h = 1
factor_cols = [f"Factor_{i}" for i in range(1,9)]
forecast_analysis(df_merged, "SPX_exret", "VOL", factor_cols, h)

"""Repeat for Walmart"""

# 1-Step Ahead Forecast, AR(1) & Factor Models
forecast_analysis(df_merged, "WMT_exret", "VOL_WMT", factor_cols, h=1)

"""AAPL - but the factor model still performs worse than AR"""

forecast_analysis(df_merged, "AAPL_exret", "VOL_AAPL", factor_cols, h=1)

"""## We try normalising the factors

Using Pre processing from sklean
"""

import numpy as np
import pandas as pd
import statsmodels.api as sm
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler

def forecast_analysis_standardise(df_merged, ret_var, vol_var, factor_cols, h):
    # 1) Prepare leads and lags
    df = df_merged.copy()
    df["ret_lead"] = df[ret_var].shift(-(h-1))
    df["vol_lead"] = df[vol_var].shift(-(h-1))
    df["ret_t"]   = df[ret_var].shift(1)
    df["vol_t"]   = df[vol_var].shift(1)

    # 2) Drop missing
    df_ret = df[["ret_lead","ret_t"] + factor_cols].dropna()
    df_vol = df[["vol_lead","vol_t"] + factor_cols].dropna()

    # 3) Train/Test split (80/20)
    split_ret = int(0.8 * len(df_ret))
    split_vol = int(0.8 * len(df_vol))

    train_ret = df_ret.iloc[:split_ret].copy()
    test_ret  = df_ret.iloc[split_ret:].copy()
    train_vol = df_vol.iloc[:split_vol].copy()
    test_vol  = df_vol.iloc[split_vol:].copy()

    # 3.1) PREPROCESSING: Standardize X and y
    scaler_X_ret = StandardScaler()
    scaler_y_ret = StandardScaler()
    scaler_X_vol = StandardScaler()
    scaler_y_vol = StandardScaler()

    X_ret_train = train_ret[["ret_t"] + factor_cols]
    X_ret_test  = test_ret[["ret_t"] + factor_cols]
    X_vol_train = train_vol[["vol_t"] + factor_cols]
    X_vol_test  = test_vol[["vol_t"] + factor_cols]

    X_ret_tr_s = pd.DataFrame(
        scaler_X_ret.fit_transform(X_ret_train),
        index=X_ret_train.index,
        columns=X_ret_train.columns)
    X_ret_te_s = pd.DataFrame(
        scaler_X_ret.transform(X_ret_test),
        index=X_ret_test.index,
        columns=X_ret_test.columns)

    X_vol_tr_s = pd.DataFrame(
        scaler_X_vol.fit_transform(X_vol_train),
        index=X_vol_train.index,
        columns=X_vol_train.columns)
    X_vol_te_s = pd.DataFrame(
        scaler_X_vol.transform(X_vol_test),
        index=X_vol_test.index,
        columns=X_vol_test.columns)

    y_ret_tr_s = scaler_y_ret.fit_transform(train_ret[["ret_lead"]]).ravel()
    y_ret_te_s = scaler_y_ret.transform(test_ret[["ret_lead"]]).ravel()
    y_vol_tr_s = scaler_y_vol.fit_transform(train_vol[["vol_lead"]]).ravel()
    y_vol_te_s = scaler_y_vol.transform(test_vol[["vol_lead"]]).ravel()

    # 4) RETURN FORECASTS

    # 4a) Factor Model
    X_tr_fac    = sm.add_constant(X_ret_tr_s)
    X_te_fac    = sm.add_constant(X_ret_te_s)
    fac_mod     = sm.OLS(y_ret_tr_s, X_tr_fac).fit()
    y_hat_fac_s = fac_mod.predict(X_te_fac)
    y_hat_fac   = scaler_y_ret.inverse_transform(
                      y_hat_fac_s.to_numpy().reshape(-1,1)
                  ).ravel()
    resid_fac   = test_ret["ret_lead"] - y_hat_fac
    rmse_fac    = np.sqrt((resid_fac**2).mean())
    llf_fac     = fac_mod.llf

    # 4b) AR(1) Benchmark
    X_tr_ar1    = sm.add_constant(X_ret_tr_s[["ret_t"]])
    X_te_ar1    = sm.add_constant(X_ret_te_s[["ret_t"]])
    ar1_mod     = sm.OLS(y_ret_tr_s, X_tr_ar1).fit()
    y_hat_ar1_s = ar1_mod.predict(X_te_ar1)
    y_hat_ar1   = scaler_y_ret.inverse_transform(
                      y_hat_ar1_s.to_numpy().reshape(-1,1)
                  ).ravel()
    resid_ar1   = test_ret["ret_lead"] - y_hat_ar1
    rmse_ar1    = np.sqrt((resid_ar1**2).mean())
    llf_ar1     = ar1_mod.llf

    print(f"Return Factor Model: RMSE={rmse_fac:.4f}, Log-Lik={llf_fac:.2f}")
    print(f"Return AR(1) Model:   RMSE={rmse_ar1:.4f}, Log-Lik={llf_ar1:.2f}")

    # 5) VOLATILITY FORECASTS

    # 5a) Factor Model
    Xv_tr_fac  = sm.add_constant(X_vol_tr_s)
    Xv_te_fac  = sm.add_constant(X_vol_te_s)
    vfac_mod   = sm.OLS(y_vol_tr_s, Xv_tr_fac).fit()
    y_hat_vf_s = vfac_mod.predict(Xv_te_fac)
    y_hat_vf   = scaler_y_vol.inverse_transform(
                      y_hat_vf_s.to_numpy().reshape(-1,1)
                  ).ravel()
    resid_vf   = test_vol["vol_lead"] - y_hat_vf
    rmse_vf    = np.sqrt((resid_vf**2).mean())
    llf_vf     = vfac_mod.llf

    # 5b) AR(1) Benchmark
    Xv_tr_ar1  = sm.add_constant(X_vol_tr_s[["vol_t"]])
    Xv_te_ar1  = sm.add_constant(X_vol_te_s[["vol_t"]])
    var1_mod   = sm.OLS(y_vol_tr_s, Xv_tr_ar1).fit()
    y_hat_v1_s = var1_mod.predict(Xv_te_ar1)
    y_hat_v1   = scaler_y_vol.inverse_transform(
                      y_hat_v1_s.to_numpy().reshape(-1,1)
                  ).ravel()
    resid_v1   = test_vol["vol_lead"] - y_hat_v1
    rmse_v1    = np.sqrt((resid_v1**2).mean())
    llf_v1     = var1_mod.llf

    print(f"Vol Factor Model: RMSE={rmse_vf:.4f}, Log-Lik={llf_vf:.2f}")
    print(f"Vol AR(1) Model:   RMSE={rmse_v1:.4f}, Log-Lik={llf_v1:.2f}")

    # ... (plots and Risk-Return section unchanged) ...
    # 6) PLOTS (unchanged; showing residuals & forecasts in original scale)
    plt.figure()
    plt.plot(resid_fac.index.to_timestamp(), resid_fac, label="Residual")
    plt.title("Return Residuals — Factor Model")
    plt.xlabel("Date"); plt.ylabel("Residual")
    plt.show()

    plt.figure()
    plt.plot(test_ret.index.to_timestamp(), test_ret["ret_lead"],    "o-", label="Actual")
    plt.plot(test_ret.index.to_timestamp(), y_hat_fac,   "x--", label="Factor")
    plt.plot(test_ret.index.to_timestamp(), y_hat_ar1,  "^--", label="AR(1)")
    plt.title(f"{h}-Step Return Forecast vs Actual")
    plt.xlabel("Date"); plt.ylabel("Excess Return"); plt.legend()
    plt.show()

    plt.figure()
    plt.plot(resid_vf.index.to_timestamp(), resid_vf, label="Residual")
    plt.title("Volatility Residuals — Factor Model")
    plt.xlabel("Date"); plt.ylabel("Residual")
    plt.show()

    plt.figure()
    plt.plot(test_vol.index.to_timestamp(), test_vol["vol_lead"],    "o-", label="Actual")
    plt.plot(test_vol.index.to_timestamp(), y_hat_vf, "x--", label="Factor")
    plt.plot(test_vol.index.to_timestamp(), y_hat_v1, "^--", label="AR(1)")
    plt.title(f"{h}-Step Volatility Forecast vs Actual")
    plt.xlabel("Date"); plt.ylabel("Realized Volatility"); plt.legend()
    plt.show()

    # 7) Risk-Return Regression (Eq. 7 from Ludvigson & Ng) — remains unchanged
    m_hat = pd.Series(y_hat_fac, index=test_ret.index)
    s_hat = pd.Series(y_hat_vf,  index=test_vol.index)
    idx   = m_hat.index.intersection(s_hat.index)
    rr_df = pd.DataFrame({
        "m_hat":     m_hat.loc[idx],
        "m_hat_lag": m_hat.loc[idx].shift(1),
        "s_hat":     s_hat.loc[idx],
        "s_hat_lag": s_hat.loc[idx].shift(1)
    }).dropna()

    X_rr  = sm.add_constant(rr_df[["s_hat","s_hat_lag","m_hat_lag"]])
    y_rr  = rr_df["m_hat"]
    rr_mod = sm.OLS(y_rr, X_rr).fit()
    hac_res = rr_mod.get_robustcov_results(cov_type='HAC', maxlags=12)
    print("\nHAC Errors:\n")
    print(hac_res.summary())

factor_cols = df_merged.columns[5:].to_list()
forecast_analysis_standardise(df_merged, "SPX_exret", "VOL", factor_cols, h=1)

"""## TO-DO: SOLUTION! We predict the factor at t+1 to then use it to predict our y at t+1

As in Ludvigson and Ng (2007) we use an AR(1) to predict our factors. Below code should be corrected to be running.
"""

import pandas as pd
import numpy as np
from statsmodels.tsa.ar_model import AutoReg
from sklearn.metrics import mean_squared_error

# assume factors_df is your original DataFrame, indexed by a DatetimeIndex

# 1) TRAIN/TEST SPLIT (80/20 by time)
n = len(factors_df)
n_train = int(n * 0.8)
train_df = factors_df.iloc[:n_train]
test_df  = factors_df.iloc[n_train:]

# containers
rmse_dict = {}
models    = {}

# 2) FIT AR(1), FORECAST TEST, COMPUTE RMSE
for col in factors_df.columns:
    # fit on train
    y_train = train_df[col].dropna()
    model   = AutoReg(y_train, lags=1, old_names=False).fit()
    models[col] = model   # save for later

    # build one-step predictions on test:
    #  pred_t = intercept + phi * y_(t-1)
    # use the full series shifted by 1
    full = pd.concat([y_train, test_df[col]])
    preds = model.params['const'] + model.params[col + '.L1'] * full.shift(1)
    preds = preds.loc[test_df.index]

    # compute RMSE
    rmse = np.sqrt(mean_squared_error(test_df[col], preds))
    rmse_dict[col] = rmse

    coef_dict = {}
    for col, model in models.items():
        params = model.params
        coef_dict[col] = {
          'intercept': params['const'],
          'phi':        params[f'{col}.L1']
        }

coef_df = pd.DataFrame.from_dict(coef_dict, orient='index')
print("\nAR(1) Coefficients for each factor:\n")
print(coef_df)

# show test RMSEs
rmse_df = pd.Series(rmse_dict, name='AR1_test_RMSE')
print(rmse_df)

# 3) ONE-STEP FORECASTS FROM 1980-01 ONWARD USING TRAINED MODELS
start = '1980-01'
slice_df = factors_df.loc[start:]

forecast_df = pd.DataFrame(index=slice_df.index, columns=slice_df.columns)

for col, model in models.items():
    params = model.params
    phi    = params[col + '.L1']
    c      = params['const']

    # forecast[t] = c + phi * actual[t-1]
    forecast_df[col] = c + phi * slice_df[col].shift(1)

# 4) UNIFIED DATAFRAME
#    join the original factors and their forecasts side by side
#    suffix forecasts with '_AR1'
forecast_df = forecast_df.add_suffix('_AR1')
unified_df  = pd.concat([slice_df, forecast_df], axis=1)

unified_df

"""ToDo: Let's compare the AR(1) coefficients of our factors to the one's of ludvigson and Ng (2007). Overall due to the different time frame, we get quite different results.

1 step ahead predictions:
We first merge DataFrames, then define our function and run the regression
"""

monthly

# Concatenate the factors DataFrame with the original DataFrame
# Reset the index of the original DataFrame to align with the factors
df_merged = pd.concat([monthly, unified_df], axis=1)
df_merged = df_merged.dropna(subset=['Factor_1', 'SPX_exret'])
df_merged

import numpy as np
import pandas as pd
import statsmodels.api as sm
import matplotlib.pyplot as plt

def forecast_analysis(df_merged, ret_var, vol_var, factor_cols_pred, h=1):
    df = df_merged.copy()

    # 1) Prepare leads and lags for Y
    df["ret_lead"] = df[ret_var].shift(-h)
    df["vol_lead"] = df[vol_var].shift(-h)
    df["ret_t"]   = df[ret_var]
    df["vol_t"]   = df[vol_var]

    # 2) Drop missing
    df_ret = df[["ret_lead","ret_t"] + factor_cols_pred].dropna()
    df_vol = df[["vol_lead","vol_t"] + factor_cols_pred].dropna()

    # 3) Train/Test split (80/20)
    split_ret = int(0.8 * len(df_ret))
    split_vol = int(0.8 * len(df_vol))

    train_ret = df_ret.iloc[:split_ret]
    test_ret  = df_ret.iloc[split_ret:]
    train_vol = df_vol.iloc[:split_vol]
    test_vol  = df_vol.iloc[split_vol:]

    # 4a) Return: Factor-Augmented
    X_tr_fac = sm.add_constant(train_ret[["ret_t"] + factor_cols_pred])
    X_te_fac = sm.add_constant(test_ret[["ret_t"] + factor_cols_pred])
    y_tr_ret = train_ret["ret_lead"]
    y_te_ret = test_ret["ret_lead"]

    fac_mod   = sm.OLS(y_tr_ret, X_tr_fac).fit()
    y_hat_fac = fac_mod.predict(X_te_fac)
    rmse_fac  = np.sqrt(((y_te_ret - y_hat_fac)**2).mean())
    print(f"Return Factor Model: RMSE={rmse_fac:.4f}")

    # 4b) Return: AR(1) benchmark
    X_tr_ar1  = sm.add_constant(train_ret[["ret_t"]])
    X_te_ar1  = sm.add_constant(test_ret[["ret_t"]])
    ar1_mod   = sm.OLS(y_tr_ret, X_tr_ar1).fit()
    y_hat_ar1 = ar1_mod.predict(X_te_ar1)
    rmse_ar1  = np.sqrt(((y_te_ret - y_hat_ar1)**2).mean())
    print(f"Return AR(1) Model:   RMSE={rmse_ar1:.4f}")

    # 5a) Volatility: Factor-Augmented
    Xv_tr_fac = sm.add_constant(train_vol[["vol_t"] + factor_cols_pred])
    Xv_te_fac = sm.add_constant(test_vol[["vol_t"] + factor_cols_pred])
    yv_tr     = train_vol["vol_lead"]
    yv_te     = test_vol["vol_lead"]

    vfac_mod  = sm.OLS(yv_tr, Xv_tr_fac).fit()
    y_hat_vf  = vfac_mod.predict(Xv_te_fac)
    rmse_vf   = np.sqrt(((yv_te - y_hat_vf)**2).mean())
    print(f"Volatility Factor Model: RMSE={rmse_vf:.4f}")

    # 5b) Volatility: AR(1) benchmark
    Xv_tr_ar1 = sm.add_constant(train_vol[["vol_t"]])
    Xv_te_ar1 = sm.add_constant(test_vol[["vol_t"]])
    var1_mod  = sm.OLS(yv_tr, Xv_tr_ar1).fit()
    y_hat_v1  = var1_mod.predict(Xv_te_ar1)
    rmse_v1   = np.sqrt(((yv_te - y_hat_v1)**2).mean())
    print(f"Volatility AR(1) Model:   RMSE={rmse_v1:.4f}")

    # 6) (Optional) Plotting as before...
    #    e.g. plt.plot(test_ret.index, y_te_ret, ...)
    #    -- same code, just replace factor series with your predictions --

    # 7) Risk-Return regression (Eq. 7):
    m_hat = pd.Series(y_hat_fac.values, index=y_te_ret.index)
    s_hat = pd.Series(y_hat_vf.values,  index=yv_te.index)
    rr_df = pd.DataFrame({
        "m_hat":     m_hat,
        "m_hat_lag": m_hat.shift(1),
        "s_hat":     s_hat,
        "s_hat_lag": s_hat.shift(1)
    }).dropna()

    X_rr = sm.add_constant(rr_df[["s_hat","s_hat_lag","m_hat_lag"]])
    y_rr = rr_df["m_hat"]
    rr_mod = sm.OLS(y_rr, X_rr).fit(cov_type='HAC', cov_kwds={'maxlags':12})
    print("\nRisk-Return HAC-corrected summary:\n")
    print(rr_mod.summary())

"""Adjust the `ret_var` and `vol_var` accordingly to the variables we want to forecast"""

# 1) Define your predicted‐factor column list:
factor_pred_cols = [f"Factor_{i}_AR1" for i in range(1,9)]

# 2) Call the analysis:
forecast_analysis(
    df_merged=df_merged,
    ret_var="SPX_exret",
    vol_var="VOL",
    factor_cols_pred=factor_pred_cols,
    h=1
)

"""3-step ahead forecast"""

# 2) Call the analysis:
forecast_analysis(
    df_merged=df_merged,
    ret_var="SPX_exret",
    vol_var="VOL",
    factor_cols_pred=factor_pred_cols,
    h=3
)

# 2) Call the analysis:
forecast_analysis(
    df_merged=df_merged,
    ret_var="SPX_exret",
    vol_var="VOL",
    factor_cols_pred=factor_pred_cols,
    h=6
)

# 2) Call the analysis:
forecast_analysis(
    df_merged=df_merged,
    ret_var="SPX_exret",
    vol_var="VOL",
    factor_cols_pred=factor_pred_cols,
    h=9
)

# 2) Call the analysis:
forecast_analysis(
    df_merged=df_merged,
    ret_var="SPX_exret",
    vol_var="VOL",
    factor_cols_pred=factor_pred_cols,
    h=12
)

"""## OLD:Extension (WIP)

### 3 step ahead forecast
"""

forecast_analysis(df_merged, "SPX_exret", "VOL", factor_cols, h=3)
forecast_analysis(df_merged, "WMT_exret", "VOL_WMT", factor_cols, h=3)

"""### 6 step ahead forecast"""

forecast_analysis(df_merged, "SPX_exret", "VOL", factor_cols, h=6)
forecast_analysis(df_merged, "WMT_exret", "VOL_WMT", factor_cols, h=6)

"""### 12-step ahead forecast"""

forecast_analysis(df_merged, "SPX_exret", "VOL", factor_cols, h=12)
forecast_analysis(df_merged, "WMT_exret", "VOL_WMT", factor_cols, h=12)

"""### WIP"""

import statsmodels.api as sm

# --- PARAMETERS ---
horizons    = [1, 6, 12]               # months ahead
factor_cols = [f"Factor_{i}" for i in range(1,9)]
max_lags    = 12

# results storage
results = []

for h in horizons:
    df = df_merged.copy()
    # 1) Create h‑month leads
    df["ret_lead"] = df["SPX_exret"].shift(-h)
    df["vol_lead"] = df["VOL"].shift(-h)
    # 2) Make up to max_lags of lags for y_t
    for i in range(max_lags):
        df[f"ret_lag_{i}"] = df["SPX_exret"].shift(i)
        df[f"vol_lag_{i}"] = df["VOL"].shift(i)
    # 3) Drop all rows with any NaN in the columns we’ll use
    ret_cols = ["ret_lead"] + [f"ret_lag_{i}" for i in range(max_lags)] + factor_cols
    vol_cols = ["vol_lead"] + [f"vol_lag_{i}" for i in range(max_lags)] + ["Factor_1"]
    df_ret = df[ret_cols].dropna()
    df_vol = df[vol_cols].dropna()

    # 4) Train/test split (80/20)
    split_ret = int(len(df_ret)*0.8)
    split_vol = int(len(df_vol)*0.8)

    # -- RETURN FORECASTS --
    train_ret = df_ret.iloc[:split_ret]
    test_ret  = df_ret.iloc[split_ret:]
    y_train   = train_ret["ret_lead"]
    y_test    = test_ret["ret_lead"]

    # (a) Factor model: const + ret_t + 8 factors
    X_tr_f = sm.add_constant(train_ret[["ret_lag_0"] + factor_cols].rename(columns={"ret_lag_0":"ret_t"}))
    X_te_f = sm.add_constant(test_ret[ ["ret_lag_0"] + factor_cols].rename(columns={"ret_lag_0":"ret_t"}))
    fac_mod = sm.OLS(y_train, X_tr_f).fit()
    y_hat_fac = fac_mod.predict(X_te_f)
    rmse_fac = np.sqrt(((y_test - y_hat_fac)**2).mean())

    # (b) AR(1) benchmark
    X_tr_1 = sm.add_constant(train_ret[["ret_lag_0"]].rename(columns={"ret_lag_0":"ret_t"}))
    X_te_1 = sm.add_constant(test_ret[ ["ret_lag_0"]].rename(columns={"ret_lag_0":"ret_t"}))
    ar1_mod = sm.OLS(y_train, X_tr_1).fit()
    y_hat_ar1 = ar1_mod.predict(X_te_1)
    rmse_ar1  = np.sqrt(((y_test - y_hat_ar1)**2).mean())

    # (c) AR(p) with p by BIC
    bic_list = []
    for p in range(1, max_lags+1):
        cols_p = [f"ret_lag_{i}" for i in range(p)]
        tmp = train_ret[["ret_lead"] + cols_p].dropna()
        y_tmp = tmp["ret_lead"]
        X_tmp = sm.add_constant(tmp[cols_p])
        m = sm.OLS(y_tmp, X_tmp).fit()
        bic_list.append((p, m.bic))
    p_opt, bic_opt = min(bic_list, key=lambda x: x[1])

    # Fit AR(p_opt) on train, forecast on test
    cols_opt = [f"ret_lag_{i}" for i in range(p_opt)]
    X_tr_p  = sm.add_constant(train_ret[cols_opt])
    X_te_p  = sm.add_constant(test_ret[cols_opt])
    ar_pmod = sm.OLS(y_train, X_tr_p).fit()
    y_hat_p = ar_pmod.predict(X_te_p)
    rmse_p  = np.sqrt(((y_test - y_hat_p)**2).mean())

    # -- VOLATILITY FORECASTS (mirror the above but using vol_…) --
    train_vol = df_vol.iloc[:split_vol]
    test_vol  = df_vol.iloc[split_vol:]
    yv_tr     = train_vol["vol_lead"]
    yv_te     = test_vol["vol_lead"]

    # (a) “Factor” model for vol: const + vol_t + Factor_1
    Xv_tr_f = sm.add_constant(train_vol[["vol_lag_0","Factor_1"]].rename(columns={"vol_lag_0":"vol_t"}))
    Xv_te_f = sm.add_constant(test_vol[ ["vol_lag_0","Factor_1"]].rename(columns={"vol_lag_0":"vol_t"}))
    vfac_mod = sm.OLS(yv_tr, Xv_tr_f).fit()
    yhat_vf  = vfac_mod.predict(Xv_te_f)
    rmse_vf  = np.sqrt(((yv_te - yhat_vf)**2).mean())

    # (b) AR(1) on vol
    Xv_tr_1 = sm.add_constant(train_vol[["vol_lag_0"]].rename(columns={"vol_lag_0":"vol_t"}))
    Xv_te_1 = sm.add_constant(test_vol[ ["vol_lag_0"]].rename(columns={"vol_lag_0":"vol_t"}))
    var1_mod = sm.OLS(yv_tr, Xv_tr_1).fit()
    yhat_v1  = var1_mod.predict(Xv_te_1)
    rmse_v1  = np.sqrt(((yv_te - yhat_v1)**2).mean())

    # (c) AR(p_opt) on vol
    bic_v = []
    for p in range(1, max_lags+1):
        cols_p = [f"vol_lag_{i}" for i in range(p)]
        tmp = train_vol[["vol_lead"] + cols_p].dropna()
        mv = sm.OLS(tmp["vol_lead"], sm.add_constant(tmp[cols_p])).fit()
        bic_v.append((p, mv.bic))
    pv_opt, bicv_opt = min(bic_v, key=lambda x: x[1])

    cols_vopt = [f"vol_lag_{i}" for i in range(pv_opt)]
    Xv_tr_p   = sm.add_constant(train_vol[cols_vopt])
    Xv_te_p   = sm.add_constant(test_vol[cols_vopt])
    varp_mod  = sm.OLS(yv_tr, Xv_tr_p).fit()
    yhat_vp   = varp_mod.predict(Xv_te_p)
    rmse_vp   = np.sqrt(((yv_te - yhat_vp)**2).mean())

    # --- COLLECT ---
    results.append({
        "horizon(m)":   h,
        # return
        "RMSE_ret_fac":  rmse_fac,
        "RMSE_ret_AR1":  rmse_ar1,
        "RMSE_ret_ARp":  rmse_p,
        "p_opt_ret":     p_opt,
        # vol
        "RMSE_vol_fac":  rmse_vf,
        "RMSE_vol_AR1":  rmse_v1,
        "RMSE_vol_ARp":  rmse_vp,
        "p_opt_vol":     pv_opt
    })

# --- SUMMARISE ---
results_df = pd.DataFrame(results)
print(results_df.to_string(index=False))

"""# Ridge and Lasso Regressions"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LassoCV, RidgeCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error

df_regu = get_data('/content/drive/MyDrive/FE_projects/2025-03.csv',transform=True)
df_regu

#from 1973-01-01to 2025-03-31

df_regu = df_regu.loc['1973-01-01':'2025-03-31']
df_regu

# Checking Data availability of tickers:
import yfinance as yf
import pandas as pd
import numpy as np

# 1) Define the tickers
SPX_TICKER  = "^GSPC"   # S&P 500 index
TBILL_TICKER = "^IRX"   # CBOE 13‑Week T‑Bill (^IRX gives the annualized % yield)
WMT_TICKER = "WMT"

# 2) Download history
#    Adjust start/end as needed
data = yf.download(
    [SPX_TICKER, TBILL_TICKER, WMT_TICKER],
    start="1973-01-01",
    end="2025-03-31",
    progress=False
)

# 3) Keep only the Adj Close columns
df_stocks = data["Close"].rename(columns={
    SPX_TICKER: "SPX_Close",
    WMT_TICKER: "WMT_Close",
    TBILL_TICKER: "Tbill_Yield"
})

# 4) Convert T‑bill from % to daily log‐yield
#    IRX is quoted as a percent annual rate, so:
df_stocks["Tbill_Yield"] = df_stocks["Tbill_Yield"] / 100            # → decimal annual rate
df_stocks["rf_daily"]    = np.log1p(df_stocks["Tbill_Yield"] / 252)   # assume 252 trading days

# 5) Compute daily SPX log‐return and excess‐return
df_stocks["spx_ret"]     = np.log(df_stocks["SPX_Close"]).diff()
df_stocks["spx_exret"]   = df_stocks["spx_ret"] - df_stocks["rf_daily"]
# same fore walmart WMT
df_stocks["wmt_ret"]     = np.log(df_stocks["WMT_Close"]).diff()
df_stocks["wmt_exret"]   = df_stocks["wmt_ret"] - df_stocks["rf_daily"]

# 6) Long Sample mean of daily excess return
Rbar = df_stocks["spx_exret"].mean()
Rbar_WMT = df_stocks["wmt_exret"].mean()

# 7) Squared Deviations will be the variance
df_stocks["sq_dev"] = (df_stocks["spx_exret"] - Rbar)**2
df_stocks["sq_dev_WMT"]= (df_stocks["wmt_exret"] - Rbar_WMT)**2

# 8) We aggregate to Monthly volatility from daily
# Sum daily numbers, then take the square-root
monthly_vol = (
    df_stocks["sq_dev"]
      .resample("ME")    # monthly groups instead of quarterly
      .sum()            # Σ (R_sk – R̄_s)^2 for k in month m
      .pipe(np.sqrt)    # √[ Σ (…) ]
      .rename("VOL")
)
monthly_vol_wmt = (
    df_stocks["sq_dev_WMT"]
      .resample("ME")    # monthly groups instead of quarterly
      .sum()            # Σ (R_sk – R̄_s)^2 for k in month m
      .pipe(np.sqrt)    # √[ Σ (…) ]
      .rename("VOL")
)

# 9) Monthly Panel
monthly = pd.DataFrame({
    "SPX_exret": df_stocks["spx_exret"].resample("ME").sum(),
    "WMT_exret": df_stocks["wmt_exret"].resample("ME").sum(),
    "Tbill_Yield": df_stocks["Tbill_Yield"].resample("ME").mean(),
    "VOL": monthly_vol,
    "VOL_WMT": monthly_vol_wmt
})

# remove day from date
monthly.index = monthly.index.to_period('M')
monthly

df_regu.index = pd.to_datetime(df_regu.index).to_period('M')

df_regu

df_regu = pd.merge(df_regu, monthly, left_index=True, right_index=True, how='left')

df_regu = df_regu.dropna()
df_regu

!pip install stargazer

# Summary Statistics for the whole data frame:
import stargazer
from stargazer.stargazer import Stargazer

dependent_vars = ['SPX_exret', 'WMT_exret', 'Tbill_Yield', 'VOL', 'VOL_WMT']
summary_all = df_regu.describe().transpose().round(3)

summary_dep = summary_all.loc[dependent_vars]
summary_exp = summary_all.drop(index=dependent_vars)

def escape_latex(name):
    return name.replace('_', r'\_').replace('%', r'\%').replace('&', r'\&')

summary_dep.index = summary_dep.index.map(escape_latex)
summary_exp.index = summary_exp.index.map(escape_latex)

latex_dep = summary_dep.to_latex(column_format='lrrrrrrrr', float_format="%.3f", caption="Summary Statistics: Dependent Variables")
latex_exp = summary_exp.to_latex(column_format='lrrrrrrrr', float_format="%.3f", caption="Summary Statistics: Explanatory Variables")

from IPython.display import display, Latex
display(Latex(latex_dep))
display(Latex(latex_exp))

# we want to collapse predictors from the original FRED-MD data set to predict returns and volatility

monthly.columns
targets = ['SPX_exret', 'WMT_exret', 'Tbill_Yield', 'VOL', 'VOL_WMT']
excluded_cols = targets
predictor_cols = [col for col in df_regu.columns if col not in excluded_cols]

split_idx = int(0.8 * len(df_regu))
train_df = df_regu.iloc[:split_idx]
test_df = df_regu.iloc[split_idx:]

results = {}

horizons = [1, 6, 12]

for target in targets:
    print(f"\n--- Forecasting {target} ---")

    X_train = train_df[predictor_cols]
    y_train = train_df[target]


    X_test = test_df[predictor_cols]
    y_test = test_df[target]

    scaler_X = StandardScaler()
    scaler_y = StandardScaler()

    X_train_scaled = scaler_X.fit_transform(X_train)
    X_test_scaled = scaler_X.transform(X_test)

    y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1,1)).ravel()
    y_test_scaled = scaler_y.transform(y_test.values.reshape(-1,1)).ravel()
    alphas = np.logspace(-4, 4, 100)

    lasso = LassoCV(alphas=alphas, cv=5).fit(X_train_scaled, y_train_scaled)
    ridge = RidgeCV(alphas=alphas).fit(X_train_scaled, y_train_scaled)

    # 1,6,12 step ahead forecasts
    forecasts_lasso = {}
    forecasts_ridge = {}

    for h in horizons:

        y_pred_lasso_scaled = lasso.predict(X_test_scaled)
        y_pred_ridge_scaled = ridge.predict(X_test_scaled)

        y_pred_lasso = scaler_y.inverse_transform(y_pred_lasso_scaled.reshape(-1,1)).ravel()
        y_pred_ridge = scaler_y.inverse_transform(y_pred_ridge_scaled.reshape(-1,1)).ravel()

        actual = y_test[h-1:].reset_index(drop=True)
        pred_lasso = pd.Series(y_pred_lasso, index=y_test.index).shift(h-1).dropna().reset_index(drop=True)
        pred_ridge = pd.Series(y_pred_ridge, index=y_test.index).shift(h-1).dropna().reset_index(drop=True)

        rmse_lasso = np.sqrt(mean_squared_error(actual, pred_lasso))
        rmse_ridge = np.sqrt(mean_squared_error(actual, pred_ridge))

        forecasts_lasso[h] = (pred_lasso, actual, rmse_lasso)
        forecasts_ridge[h] = (pred_ridge, actual, rmse_ridge)

        print(f"  Horizon {h}: Lasso RMSE={rmse_lasso:.4f}, Ridge RMSE={rmse_ridge:.4f}")


    results[target] = {
        "lasso": forecasts_lasso,
        "ridge": forecasts_ridge,
        "model_lasso": lasso,
        "model_ridge": ridge
    }

# Define new plotting function that saves PNGs
def plot_forecasts(pred, actual, title, filename):
    plt.figure(figsize=(10,6))
    plt.plot(actual.index, actual, label="Actual", marker='o')
    plt.plot(pred.index, pred, label="Forecast", marker='x')
    plt.title(title)
    plt.xlabel("Time")
    plt.ylabel("Value")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(filename, dpi=300)
    plt.close()

os.makedirs("FE_projects_collabs\forecast_plots", exist_ok=True)

# Loop and save plots for each target and horizon
for target in targets:
    for h in horizons:
        pred_lasso, actual_lasso, _ = results[target]["lasso"][h]
        pred_ridge, actual_ridge, _ = results[target]["ridge"][h]

        file_lasso = f"forecast_plots/{target}_lasso_h{h}.png"
        file_ridge = f"forecast_plots/{target}_ridge_h{h}.png"

        plot_forecasts(pred_lasso, actual_lasso, f"{target} — Lasso Forecast (h={h})", file_lasso)
        plot_forecasts(pred_ridge, actual_ridge, f"{target} — Ridge Forecast (h={h})", file_ridge)

# Plotting function
def plot_forecasts(pred, actual, title):
    plt.figure(figsize=(10,6))
    plt.plot(actual.index, actual, label="Actual", marker='o')
    plt.plot(pred.index, pred, label="Forecast", marker='x')
    plt.title(title)
    plt.xlabel("Time")
    plt.ylabel("Value")
    plt.legend()
    plt.grid(True)
    plt.show()

# Example: plot for each target and each horizon
for target in targets:
    for h in horizons:
        pred_lasso, actual_lasso, _ = results[target]["lasso"][h]
        pred_ridge, actual_ridge, _ = results[target]["ridge"][h]

        plot_forecasts(pred_lasso, actual_lasso, f"{target} — Lasso Forecast (h={h})")
        plot_forecasts(pred_ridge, actual_ridge, f"{target} — Ridge Forecast (h={h})")

"""Still to do:

Data description
Check tomorrow the forecasts for 6 and 12
Do AR(1) with Factors in Prediction again
Describe Results --> RMSE comparision
"""



"""# Winsorized Data Analysis - FINAL OUTPUT"""

import pandas as pd
import numpy as np
# Remove the first -- second in data frame -- row (which held the tcodes)
# df = get_data("FE_projects/2025-03.csv",transform=True)
df = get_data('/content/drive/MyDrive/FE_projects/2025-03.csv',transform=True)
#df = get_data('2025-03.csv',transform=True)

# make 1960:3 the start to 2014:12
df=df.iloc[12:-2,:]
df

# Winsorize AAPL_exret and VOL_AAPL at the 1st and 99th percentiles
for col in df.columns:
    lower = df[col].quantile(0.01)
    upper = df[col].quantile(0.99)
    df[col] = df[col].clip(lower, upper)
df

"""## PCA"""

# Check for optimal amount of factors via BIC
optimal_components, bic_values = select_optimal_components(standardized_df, max_components=10)
print(f"Optimal number of components: {optimal_components}")

bic_values

standardized_df, stats = standardize_dataframe(df)
num_factors = 8
F, Lambda, X_complete = em_dynamic_factor_balanced_init(standardized_df, num_factors)

# removing the first transformation row significantly improve the graphs!
import matplotlib.pyplot as plt
plt.plot(F[:,0], label='factor 1')
plt.plot(F[:,1], label='factor 2')
plt.plot(F[:,2], label='factor 3')
plt.plot(F[:,3], label='factor 4')
plt.plot(F[:,4], label='factor 5')
plt.plot(F[:,5], label='factor 6')
plt.plot(F[:,6], label='factor 7')
plt.plot(F[:,7], label='factor 8')
plt.legend();

# Compute the cumulative R² for each series as factors are added.
R2_matrix = compute_R2_values(X_complete, F)

# Then compute the incremental R² (mR²) for each factor for each series and the average across series.
mR2_individual, mR2_average = compute_incremental_R2(R2_matrix)

series_names = df.columns.tolist()

# Optionally, create column labels for the factors
factor_labels = [f'Factor_{i+1}' for i in range(num_factors)]

# Create a DataFrame from the mR2_individual array with the desired indices and columns
mR2_df = pd.DataFrame(mR2_individual, index=series_names, columns=factor_labels)
mR2_df

mR2_df.sort_values(by='Factor_1', ascending=False).head(10)

print(mR2_average)
sum(mR2_average)

"""## Factor Prediction"""

# We create our factors dataframe for the forecasting below
factors_df = pd.DataFrame(F, columns=[f"Factor_{i+1}" for i in range(8)])
factors_df.index = df.index
factors_df.index = factors_df.index.to_period('M')
factors_df

from statsmodels.tsa.ar_model import AutoReg
from sklearn.metrics import mean_squared_error

# assume factors_df is your original DataFrame, indexed by a DatetimeIndex
# 1) TRAIN/TEST SPLIT (80/20 by time)
n = len(factors_df)
n_train = int(n * 0.8)
train_df = factors_df.iloc[:n_train]
test_df  = factors_df.iloc[n_train:]

# containers
rmse_dict = {}
models    = {}

# 2) FIT AR(1), FORECAST TEST, COMPUTE RMSE
for col in factors_df.columns:
    # fit on train
    y_train = train_df[col].dropna()
    model   = AutoReg(y_train, lags=1, old_names=False).fit()
    models[col] = model   # save for later

    # build one-step predictions on test:
    #  pred_t = intercept + phi * y_(t-1)
    # use the full series shifted by 1
    full = pd.concat([y_train, test_df[col]])
    preds = model.params['const'] + model.params[col + '.L1'] * full.shift(1)
    preds = preds.loc[test_df.index]

    # compute RMSE
    rmse = np.sqrt(mean_squared_error(test_df[col], preds))
    rmse_dict[col] = rmse

    coef_dict = {}
    for col, model in models.items():
        params = model.params
        coef_dict[col] = {
          'intercept': params['const'],
          'phi':        params[f'{col}.L1']
        }

coef_df = pd.DataFrame.from_dict(coef_dict, orient='index')
print("\nAR(1) Coefficients for each factor:\n")
print(coef_df)

# show test RMSEs
rmse_df = pd.Series(rmse_dict, name='AR1_test_RMSE')
print(rmse_df)

# 3) ONE-STEP FORECASTS FROM 1980-01 ONWARD USING TRAINED MODELS
start = '1980-01'
slice_df = factors_df.loc[start:]

forecast_df = pd.DataFrame(index=slice_df.index, columns=slice_df.columns)

for col, model in models.items():
    params = model.params
    phi    = params[col + '.L1']
    c      = params['const']

    # forecast[t] = c + phi * actual[t-1]
    forecast_df[col] = c + phi * slice_df[col].shift(1)

# 4) UNIFIED DATAFRAME
#    join the original factors and their forecasts side by side
#    suffix forecasts with '_AR1'
forecast_df = forecast_df.add_suffix('_AR1')
unified_df  = pd.concat([slice_df, forecast_df], axis=1)
unified_df

"""## Stock Market Data"""

import yfinance as yf
# 1) Define the tickers
SPX_TICKER  = "^GSPC"   # S&P 500 index
TBILL_TICKER = "^IRX"   # CBOE 13‑Week T‑Bill (^IRX gives the annualized % yield)
WMT_TICKER = "WMT"
AAPL_TICKER = "AAPL"
# 2) Download history
#    Adjust start/end as needed
data = yf.download(
    [SPX_TICKER, TBILL_TICKER, WMT_TICKER, AAPL_TICKER],
    start="1981-01-01",
    end="2025-03-31",
    progress=False
)

# 3) Keep only the Adj Close columns
df_stocks = data["Close"].rename(columns={
    SPX_TICKER: "SPX_Close",
    WMT_TICKER: "WMT_Close",
    AAPL_TICKER: "AAPL_Close",
    TBILL_TICKER: "Tbill_Yield"
})

# 4) Convert T‑bill from % to daily log‐yield
#    IRX is quoted as a percent annual rate, so:
df_stocks["Tbill_Yield"] = df_stocks["Tbill_Yield"] / 100            # → decimal annual rate
df_stocks["rf_daily"]    = np.log1p(df_stocks["Tbill_Yield"] / 252)   # assume 252 trading days

# 5) Compute daily SPX log‐return and excess‐return
df_stocks["spx_ret"]     = np.log(df_stocks["SPX_Close"]).diff()
df_stocks["spx_exret"]   = df_stocks["spx_ret"] - df_stocks["rf_daily"]
# same fore walmart WMT
df_stocks["wmt_ret"]     = np.log(df_stocks["WMT_Close"]).diff()
df_stocks["wmt_exret"]   = df_stocks["wmt_ret"] - df_stocks["rf_daily"]
# same for AAPL
df_stocks["aapl_ret"]     = np.log(df_stocks["AAPL_Close"]).diff()
df_stocks["aapl_exret"]   = df_stocks["aapl_ret"] - df_stocks["rf_daily"]

# 6) Long Sample mean of daily excess return
Rbar = df_stocks["spx_exret"].mean()
Rbar_WMT = df_stocks["wmt_exret"].mean()
Rbar_AAPL = df_stocks["aapl_exret"].mean()

# 7) Squared Deviations will be the variance
df_stocks["sq_dev"] = (df_stocks["spx_exret"] - Rbar)**2
df_stocks["sq_dev_WMT"]= (df_stocks["wmt_exret"] - Rbar_WMT)**2
df_stocks["sq_dev_AAPL"]= (df_stocks["aapl_exret"] - Rbar_AAPL)**2

# 8) We aggregate to Monthly volatility from daily
# Sum daily numbers, then take the square-root
monthly_vol = (
    df_stocks["sq_dev"]
      .resample("ME")    # monthly groups instead of quarterly
      .sum()            # Σ (R_sk – R̄_s)^2 for k in month m
      .pipe(np.sqrt)    # √[ Σ (…) ]
      .rename("VOL")
)
monthly_vol_wmt = (
    df_stocks["sq_dev_WMT"]
      .resample("ME")    # monthly groups instead of quarterly
      .sum()            # Σ (R_sk – R̄_s)^2 for k in month m
      .pipe(np.sqrt)    # √[ Σ (…) ]
      .rename("VOL")
)
monthly_vol_aapl = (
    df_stocks["sq_dev_AAPL"]
      .resample("ME")    # monthly groups instead of quarterly
      .sum()            # Σ (R_sk – R̄_s)^2 for k in month m
      .pipe(np.sqrt)
      .rename("VOL")
)

# 9) Monthly Panel
monthly = pd.DataFrame({
    "SPX_exret": df_stocks["spx_exret"].resample("ME").sum(),
    "WMT_exret": df_stocks["wmt_exret"].resample("ME").sum(),
    "AAPL_exret": df_stocks["aapl_exret"].resample("ME").sum(),
    "Tbill_Yield": df_stocks["Tbill_Yield"].resample("ME").mean(),
    "VOL": monthly_vol,
    "VOL_WMT": monthly_vol_wmt,
    "VOL_AAPL": monthly_vol_aapl
})

# remove day from date
monthly.index = monthly.index.to_period('M')
monthly

# we merged our dataframes for the regressions below
# Reset the index of the original DataFrame to align with the factors
df_merged = pd.concat([monthly, unified_df], axis=1)
df_merged = df_merged.dropna(subset=['Factor_1', 'SPX_exret'])
# drop the first row due to not having a forecast
df_merged = df_merged.iloc[1:]
df_merged

"""## Regression

### Function code
"""

import numpy as np
import pandas as pd
import statsmodels.api as sm

def forecast_analysis(df_merged, ret_var, vol_var, factor_cols_pred,
                      max_ret_lags=1, max_fac=8, h=1):
    df = df_merged.copy()

    # 1) prepare leads and lags for Y
    df[f"{ret_var}_lead"] = df[ret_var].shift(-h)
    for lag in range(1, max_ret_lags+1):
        df[f"{ret_var}_lag{lag}"] = df[ret_var].shift(lag)
    df[f"{vol_var}_lead"] = df[vol_var].shift(-h)
    df["vol_t"] = df[vol_var]

    # 2) drop missing
    ret_cols = [f"{ret_var}_lead"] + [f"{ret_var}_lag{lag}" for lag in range(1, max_ret_lags+1)]
    df_ret = df[ret_cols + factor_cols_pred].dropna()
    df_vol = df[[f"{vol_var}_lead","vol_t"] + factor_cols_pred].dropna()

    # 3) train/test split
    split_ret = int(0.8 * len(df_ret))
    split_vol = int(0.8 * len(df_vol))
    train_ret, test_ret = df_ret.iloc[:split_ret], df_ret.iloc[split_ret:]
    train_vol, test_vol = df_vol.iloc[:split_vol], df_vol.iloc[split_vol:]

    y_tr_ret = train_ret[f"{ret_var}_lead"]
    y_te_ret = test_ret[f"{ret_var}_lead"]

    # 4) select ret‐lags & number of factors by BIC on the train set
    best_bic, best_cfg = np.inf, None
    for nl in range(1, max_ret_lags+1):
        ret_lag_cols = [f"{ret_var}_lag{lag}" for lag in range(1, nl+1)]
        for k in range(1, max_fac+1):
            Xtr = sm.add_constant(train_ret[ret_lag_cols + factor_cols_pred[:k]])
            m = sm.OLS(y_tr_ret, Xtr).fit()
            if m.bic < best_bic:
                best_bic, best_cfg = m.bic, (nl, k)

    nl_best, k_best = best_cfg

    # re‐fit return factor model
    ret_lag_cols = [f"{ret_var}_lag{lag}" for lag in range(1, nl_best+1)]
    fac_cols_ret = factor_cols_pred[:k_best]
    X_tr_fac = sm.add_constant(train_ret[ret_lag_cols + fac_cols_ret])
    X_te_fac = sm.add_constant(test_ret[ret_lag_cols + fac_cols_ret])
    fac_mod   = sm.OLS(y_tr_ret, X_tr_fac).fit()
    y_hat_fac = fac_mod.predict(X_te_fac)
    rmse_fac  = np.sqrt(((y_te_ret - y_hat_fac)**2).mean())

    # AR(1) benchmark for returns
    X_tr_ar1  = sm.add_constant(train_ret[[f"{ret_var}_lag1"]])
    X_te_ar1  = sm.add_constant(test_ret[[f"{ret_var}_lag1"]])
    ar1_mod   = sm.OLS(y_tr_ret, X_tr_ar1).fit()
    y_hat_ar1 = ar1_mod.predict(X_te_ar1)
    rmse_ar1  = np.sqrt(((y_te_ret - y_hat_ar1)**2).mean())

    # 5) volatility side: pick # factors by BIC
    yv_tr, yv_te = train_vol[f"{vol_var}_lead"], test_vol[f"{vol_var}_lead"]
    best_bic_v, best_k_v = np.inf, None
    for k in range(1, max_fac+1):
        Xv = sm.add_constant(train_vol[["vol_t"] + factor_cols_pred[:k]])
        mv = sm.OLS(yv_tr, Xv).fit()
        if mv.bic < best_bic_v:
            best_bic_v, best_k_v = mv.bic, k

    fac_cols_vol = factor_cols_pred[:best_k_v]
    Xv_tr_fac = sm.add_constant(train_vol[["vol_t"] + fac_cols_vol])
    Xv_te_fac = sm.add_constant(test_vol[["vol_t"] + fac_cols_vol])
    vfac_mod  = sm.OLS(yv_tr, Xv_tr_fac).fit()
    y_hat_vf  = vfac_mod.predict(Xv_te_fac)
    rmse_vf   = np.sqrt(((yv_te - y_hat_vf)**2).mean())

    # AR(1) benchmark for volatility
    Xv_tr_ar1 = sm.add_constant(train_vol[["vol_t"]])
    Xv_te_ar1 = sm.add_constant(test_vol[["vol_t"]])
    var1_mod  = sm.OLS(yv_tr, Xv_tr_ar1).fit()
    y_hat_v1  = var1_mod.predict(Xv_te_ar1)
    rmse_v1   = np.sqrt(((yv_te - y_hat_v1)**2).mean())

    # return everything in a dict
    return {
        "horizon":      h,
        "ret_lags":     nl_best,
        "ret_factors":  k_best,
        "rmse_fac_ret": rmse_fac,
        "rmse_ar1_ret": rmse_ar1,
        "vol_factors":  best_k_v,
        "rmse_fac_vol": rmse_vf,
        "rmse_ar1_vol": rmse_v1
    }

# Raw factor names (omit any “_ARMA” columns)
factor_cols = [c for c in df_merged.columns
               if c.startswith("Factor_") and not c.endswith("_AR1")]

"""### Forecasts via BIC"""

# --- now loop over assets & horizons ---
horizons = [1, 3, 6, 9, 12, 24]
assets   = [
    ("SPX_exret",   "VOL"),
    ("WMT_exret", "VOL_WMT"),
    ("AAPL_exret", "VOL_AAPL")
]

all_results = []
for ret_var, vol_var in assets:
    for h in horizons:
        res = forecast_analysis(
            df_merged=df_merged,              # or df_merged / df_wins
            ret_var=ret_var,
            vol_var=vol_var,
            factor_cols_pred=factor_cols,
            # max_ret_lags=4,
            max_fac=8,
            h=h
        )
        res["asset"] = ret_var.split("_")[0]
        all_results.append(res)

# build a DataFrame for easy comparison
summary = pd.DataFrame(all_results)
summary = summary.set_index(["asset","horizon"])
print(summary)

"""### 3-factor model forecast"""

import statsmodels.api as sm
import numpy as np

def forecast_analysis_manual(
    df,
    ret_var,
    vol_var,
    factor_cols,
    h,
    ret_factors,
    vol_factors
):
    # 1) copy & build leads and 1-lag
    df2 = df.copy().sort_index()
    df2[f"{ret_var}_lead"] = df2[ret_var].shift(-h)
    df2[f"{ret_var}_lag1"] = df2[ret_var].shift(1)
    df2[f"{vol_var}_lead"] = df2[vol_var].shift(-h)
    df2["vol_t"]           = df2[vol_var]

    # 2) drop NAs & split into train/test
    df_ret = df2[[f"{ret_var}_lead", f"{ret_var}_lag1"] + factor_cols].dropna()
    df_vol = df2[[f"{vol_var}_lead", "vol_t"] + factor_cols].dropna()

    split_ret = int(0.8 * len(df_ret))
    train_ret, test_ret = df_ret.iloc[:split_ret], df_ret.iloc[split_ret:]

    split_vol = int(0.8 * len(df_vol))
    train_vol, test_vol = df_vol.iloc[:split_vol], df_vol.iloc[split_vol:]

    results = {"horizon": h, "ret_factors": ret_factors, "vol_factors": vol_factors}

    # 3) Factor-augmented return forecast (no ret lags)
    y_tr_ret = train_ret[f"{ret_var}_lead"]
    y_te_ret = test_ret[f"{ret_var}_lead"]

    X_tr_fac = sm.add_constant(train_ret[factor_cols[:ret_factors]])
    X_te_fac = sm.add_constant(test_ret[factor_cols[:ret_factors]])

    fac_mod   = sm.OLS(y_tr_ret, X_tr_fac).fit()
    y_hat_fac = fac_mod.predict(X_te_fac)
    results["rmse_fac_ret"] = np.sqrt(((y_te_ret - y_hat_fac)**2).mean())
    results["coef_fac_ret"] = fac_mod.params.to_dict()

    # 4) AR(1) benchmark for returns
    X_tr_ar1 = sm.add_constant(train_ret[f"{ret_var}_lag1"])
    X_te_ar1 = sm.add_constant(test_ret[f"{ret_var}_lag1"])

    ar1_mod   = sm.OLS(y_tr_ret, X_tr_ar1).fit()
    y_hat_ar1 = ar1_mod.predict(X_te_ar1)
    results["rmse_ar1_ret"] = np.sqrt(((y_te_ret - y_hat_ar1)**2).mean())
    results["coef_ar1_ret"] = ar1_mod.params.to_dict()

    # 5) Factor-augmented volatility forecast
    y_tr_vol = train_vol[f"{vol_var}_lead"]
    y_te_vol = test_vol[f"{vol_var}_lead"]

    Xv_tr_fac = sm.add_constant(train_vol[["vol_t"] + factor_cols[:vol_factors]])
    Xv_te_fac = sm.add_constant(test_vol[["vol_t"] + factor_cols[:vol_factors]])

    vfac_mod  = sm.OLS(y_tr_vol, Xv_tr_fac).fit()
    y_hat_vf  = vfac_mod.predict(Xv_te_fac)
    results["rmse_fac_vol"] = np.sqrt(((y_te_vol - y_hat_vf)**2).mean())
    results["coef_fac_vol"] = vfac_mod.params.to_dict()

    # 6) AR(1) benchmark for volatility
    Xv_tr_ar1 = sm.add_constant(train_vol[["vol_t"]])
    Xv_te_ar1 = sm.add_constant(test_vol[["vol_t"]])

    var1_mod  = sm.OLS(y_tr_vol, Xv_tr_ar1).fit()
    y_hat_v1  = var1_mod.predict(Xv_te_ar1)
    results["rmse_ar1_vol"] = np.sqrt(((y_te_vol - y_hat_v1)**2).mean())
    results["coef_ar1_vol"] = var1_mod.params.to_dict()

    return results

# ----------------------------------------------------------------
# YOUR MANUAL CONFIG: for each horizon, how many factors to use
manual_config = {
    1:  {"ret_factors": 3, "vol_factors": 3},
    3:  {"ret_factors": 3, "vol_factors": 3},
    6:  {"ret_factors": 3, "vol_factors": 3},
    9:  {"ret_factors": 3, "vol_factors": 3},
    12: {"ret_factors": 3, "vol_factors": 3},
    24: {"ret_factors": 3, "vol_factors": 3},
}

horizons = [1,3,6,9,12,24]
assets   = [
    ("SPX_exret","VOL"),
    ("WMT_exret","VOL_WMT"),
    ("AAPL_exret","VOL_AAPL")
]

all_results = []
coef_rows   = []

for ret_var, vol_var in assets:
    asset_name = ret_var.split("_")[0]
    for h in horizons:
        cfg = manual_config[h]
        res = forecast_analysis_manual(
            df=            df_merged,
            ret_var=       ret_var,
            vol_var=       vol_var,
            factor_cols=   factor_cols,
            h=             h,
            ret_factors=   cfg["ret_factors"],
            vol_factors=   cfg["vol_factors"],
        )
        # add identifying info
        res["asset"]   = asset_name
        all_results.append(res)

        # pull out each of the 4 sets of coefficients
        for model_key, model_name in [
            ("coef_fac_ret", "FactorOnlyRet"),
            ("coef_ar1_ret", "AR1Ret"),
            ("coef_fac_vol", "FactorOnlyVol"),
            ("coef_ar1_vol", "AR1Vol")
        ]:
            coefs = res[model_key]
            for param, value in coefs.items():
                coef_rows.append({
                    "asset":    asset_name,
                    "horizon":  h,
                    "model":    model_name,
                    "parameter":param,
                    "value":    value
                })

#  Build summary RMSE table
summary_factors = (
    pd.DataFrame(all_results)
      .set_index(["asset","horizon"])
      .loc[:, ["ret_factors","rmse_fac_ret","rmse_ar1_ret",
                "vol_factors","rmse_fac_vol","rmse_ar1_vol"]]
)
print("\nForecast RMSE / Configuration:\n", summary_factors)

#  Build long‐form coefficients table
summary_coefs = pd.DataFrame(coef_rows).set_index(
    ["asset","horizon","model","parameter"]
)
print("\nModel Coefficients:\n", summary_coefs)

print(summary_coefs.to_string())

import statsmodels.api as sm
import numpy as np
import pandas as pd

def forecast_analysis_manual(
    df,
    ret_var,
    vol_var,
    factor_cols,
    h,
    ret_factors,
    vol_factors
):
    # 1) copy & build leads and 1-lag
    df2 = df.copy().sort_index()
    df2[f"{ret_var}_lead"] = df2[ret_var].shift(-h)
    df2[f"{ret_var}_lag1"]  = df2[ret_var].shift(1)
    df2[f"{vol_var}_lead"]  = df2[vol_var].shift(-h)
    df2["vol_t"]            = df2[vol_var]

    # 2) drop NAs & split into train/test
    df_ret = df2[[f"{ret_var}_lead", f"{ret_var}_lag1"] + factor_cols].dropna()
    df_vol = df2[[f"{vol_var}_lead", "vol_t"] + factor_cols].dropna()

    split_ret = int(0.8 * len(df_ret))
    train_ret, test_ret = df_ret.iloc[:split_ret], df_ret.iloc[split_ret:]

    split_vol = int(0.8 * len(df_vol))
    train_vol, test_vol = df_vol.iloc[:split_vol], df_vol.iloc[split_vol:]

    results = {
        "horizon":      h,
        "ret_factors":  ret_factors,
        "vol_factors":  vol_factors
    }

    # 3) Factor‐augmented return forecast
    y_tr_ret    = train_ret[f"{ret_var}_lead"]
    y_te_ret    = test_ret [f"{ret_var}_lead"]
    X_tr_fac    = sm.add_constant(train_ret[factor_cols[:ret_factors]])
    X_te_fac    = sm.add_constant(test_ret [factor_cols[:ret_factors]])
    fac_mod     = sm.OLS(y_tr_ret, X_tr_fac).fit()
    y_hat_fac   = fac_mod.predict(X_te_fac)
    results["rmse_fac_ret"]  = np.sqrt(((y_te_ret - y_hat_fac)**2).mean())
    results["coef_fac_ret"]  = fac_mod.params .to_dict()
    results["p_fac_ret"]     = fac_mod.pvalues.to_dict()

    # 4) AR(1) benchmark for returns
    X_tr_ar1 = sm.add_constant(train_ret[[f"{ret_var}_lag1"]])
    X_te_ar1 = sm.add_constant(test_ret [[f"{ret_var}_lag1"]])
    ar1_mod  = sm.OLS(y_tr_ret, X_tr_ar1).fit()
    y_hat_ar1= ar1_mod.predict(X_te_ar1)
    results["rmse_ar1_ret"]  = np.sqrt(((y_te_ret - y_hat_ar1)**2).mean())
    results["coef_ar1_ret"]  = ar1_mod.params .to_dict()
    results["p_ar1_ret"]     = ar1_mod.pvalues.to_dict()

    # 5) Factor‐augmented volatility forecast
    y_tr_vol    = train_vol[f"{vol_var}_lead"]
    y_te_vol    = test_vol [f"{vol_var}_lead"]
    Xv_tr_fac   = sm.add_constant(train_vol[["vol_t"] + factor_cols[:vol_factors]])
    Xv_te_fac   = sm.add_constant(test_vol [ ["vol_t"] + factor_cols[:vol_factors]])
    vfac_mod    = sm.OLS(y_tr_vol, Xv_tr_fac).fit()
    y_hat_vf    = vfac_mod.predict(Xv_te_fac)
    results["rmse_fac_vol"]  = np.sqrt(((y_te_vol - y_hat_vf)**2).mean())
    results["coef_fac_vol"]  = vfac_mod.params .to_dict()
    results["p_fac_vol"]     = vfac_mod.pvalues.to_dict()

    # 6) AR(1) benchmark for volatility
    Xv_tr_ar1 = sm.add_constant(train_vol[["vol_t"]])
    Xv_te_ar1 = sm.add_constant(test_vol [["vol_t"]])
    var1_mod  = sm.OLS(y_tr_vol, Xv_tr_ar1).fit()
    y_hat_v1  = var1_mod.predict(Xv_te_ar1)
    results["rmse_ar1_vol"]  = np.sqrt(((y_te_vol - y_hat_v1)**2).mean())
    results["coef_ar1_vol"]  = var1_mod.params .to_dict()
    results["p_ar1_vol"]     = var1_mod.pvalues.to_dict()

    return results

# ----------------------------------------------------------------
# Build results and coefficients tables as before, but now also including p-values:

all_results = []
coef_rows   = []

for ret_var, vol_var in assets:
    asset_name = ret_var.split("_")[0]
    for h in horizons:
        cfg = manual_config[h]
        res = forecast_analysis_manual(
            df=            df_merged,
            ret_var=       ret_var,
            vol_var=       vol_var,
            factor_cols=   factor_cols,
            h=             h,
            ret_factors=   cfg["ret_factors"],
            vol_factors=   cfg["vol_factors"],
        )
        res["asset"], res["horizon"] = asset_name, h
        all_results.append(res)

        # For each model, emit rows for both coef and pvalue
        for model_key, model_name in [
            ("coef_fac_ret", "FactorAug_AR1_RET"),
            ("coef_ar1_ret", "AR1_RET"),
            ("coef_fac_vol", "FactorAug_AR1_VOL"),
            ("coef_ar1_vol", "AR1_VOL")
        ]:
            coefs  = res[ model_key ]
            pvals  = res[ model_key.replace("coef_", "p_") ]
            for param in coefs:
                coef_rows.append({
                    "asset":     asset_name,
                    "horizon":   h,
                    "model":     model_name,
                    "parameter": param,
                    "estimate":  coefs[param],
                    "p_value":   pvals[param]
                })

summary_factors = (
    pd.DataFrame(all_results)
      .set_index(["asset","horizon"])
      .loc[:, ["ret_factors","rmse_fac_ret","rmse_ar1_ret",
               "vol_factors","rmse_fac_vol","rmse_ar1_vol"]]
)

summary_coefs = (
    pd.DataFrame(coef_rows)
      .set_index(["asset","horizon","model","parameter"])
)

print(summary_coefs.to_string())

summary_coefs

"""## 8-factor model forecasts"""

manual_config = {
    1:  {"ret_factors": 8, "vol_factors": 8},
    3:  {"ret_factors": 8, "vol_factors": 8},
    6:  {"ret_factors": 8, "vol_factors": 8},
    9:  {"ret_factors": 8, "vol_factors": 8},
    12: {"ret_factors": 8, "vol_factors": 8},
    24: {"ret_factors": 8, "vol_factors": 8},
}

all_results = []
for ret_var, vol_var in assets:
    for h in horizons:
        cfg = manual_config[h]
        res = forecast_analysis_manual(
            df=            df_merged,           # or your winsorized df
            ret_var=       ret_var,
            vol_var=       vol_var,
            factor_cols=   factor_pred_cols,
            h=             h,
            ret_factors=   cfg["ret_factors"],
            vol_factors=   cfg["vol_factors"],
        )
        res["asset"] = ret_var.split("_")[0]
        all_results.append(res)

# Build summary table
summary_factors = pd.DataFrame(all_results).set_index(["asset","horizon"])
print(summary_factors)

"""# Ridge and Lasso on Winsorized data"""

import warnings
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LassoCV, RidgeCV
from sklearn.metrics import mean_squared_error
from sklearn.exceptions import ConvergenceWarning
from sklearn.model_selection import TimeSeriesSplit

# We merged our Macrovariables dataframe with our stock market dataframe
# remove day from date for df as we did for stock market data "monthly"
df.index = df.index.to_period('M')
df_regu = pd.concat([monthly, df], axis=1)
df_regu = df_regu.dropna(subset=['RPI', 'SPX_exret'])
df_regu

"""we look at nas and fill them using the EM-algorithm"""

df_regu.isna().sum().sum()

def em_pca_impute(df, num_factors=5, tol=1e-4, max_iter=100):
    """
    Impute missing values via iterative PCA (EM‐style).
    df           : DataFrame with NaNs to impute
    num_factors  : number of principal components to keep
    tol          : convergence tolerance on imputed entries
    max_iter     : max number of EM iterations
    """
    X = df.values.astype(float)
    mask = ~np.isnan(X)         # True where observed
    # 1) initial fill: column means
    col_means = np.nanmean(X, axis=0)
    X_imp = np.where(mask, X, col_means)

    for it in range(max_iter):
        # 2) SVD on current fill
        U, s, Vt = svd(X_imp, full_matrices=False)
        # keep top k components
        Uk = U[:, :num_factors]
        sk = s[:num_factors]
        Vk = Vt[:num_factors, :]
        # reconstruct
        X_hat = (Uk * sk).dot(Vk)
        # 3) update only the missing entries
        X_new = X.copy()
        X_new[~mask] = X_hat[~mask]
        # 4) check convergence on missing entries
        diff = norm(X_new[~mask] - X_imp[~mask])
        denom = norm(X_imp[~mask])
        if denom == 0 or diff/denom < tol:
            print(f"EM‐PCA converged in {it+1} iterations.")
            X_imp = X_new
            break
        X_imp = X_new

    return pd.DataFrame(X_imp, index=df.index, columns=df.columns)

# 1) Impute
df_imputed = em_pca_impute(df_regu, num_factors=10, tol=1e-4, max_iter=100)

"""## Summary Statistics if needed"""

!pip install stargazer

"""## Predictions"""

# --- 1) SETTINGS ---
warnings.filterwarnings("ignore", category=ConvergenceWarning)

targets    = ['SPX_exret','WMT_exret','AAPL_exret','VOL','VOL_WMT','VOL_AAPL']
predictors = [c for c in df_imputed.columns if c not in targets]
horizons   = [1,3,6,9,12,24]
alphas     = np.logspace(-4,4,100)

# Use a time-series split for CV
tscv = TimeSeriesSplit(n_splits=5)

# --- 2) SPLIT DATA ---
split = int(0.8 * len(df_imputed))
train, test = df_imputed.iloc[:split], df_imputed.iloc[split:]

# --- 3) CONTAINERS ---
forecast_store = {t: {'lasso': {}, 'ridge': {}} for t in targets}
results_list   = []

# --- 4) FIT & FORECAST ---
for t in targets:
    X_tr, y_tr = train[predictors], train[t]
    X_te, y_te = test[predictors],  test[t]

    # Pipelines with time-series CV
    lasso_pipe = make_pipeline(
        StandardScaler(),
        LassoCV(alphas=alphas, cv=tscv, max_iter=5000)
    )
    ridge_pipe = make_pipeline(
        StandardScaler(),
        RidgeCV(alphas=alphas, cv=tscv)
    )

    # Fit
    lasso_pipe.fit(X_tr, y_tr)
    ridge_pipe.fit(X_tr, y_tr)

    # Forecast on test set
    yhat_l = pd.Series(lasso_pipe.predict(X_te), index=test.index)
    yhat_r = pd.Series(ridge_pipe.predict(X_te), index=test.index)

    # Evaluate each horizon
    for h in horizons:
        actual     = y_te.shift(-h+1).dropna()
        pred_lasso = yhat_l.shift(h-1).dropna()
        pred_ridge = yhat_r.shift(h-1).dropna()

        actual, pred_lasso = actual.align(pred_lasso, join='inner')
        actual, pred_ridge = actual.align(pred_ridge, join='inner')

        rmse_l = np.sqrt(mean_squared_error(actual, pred_lasso))
        rmse_r = np.sqrt(mean_squared_error(actual, pred_ridge))

        forecast_store[t]['lasso'][h] = (pred_lasso, actual)
        forecast_store[t]['ridge'][h] = (pred_ridge, actual)

        results_list.append({
            'target':          t,
            'horizon':         h,
            'rmse_lasso':      rmse_l,
            'rmse_ridge':      rmse_r,
            'n_nonzero_lasso': np.sum(lasso_pipe.named_steps['lassocv'].coef_ != 0),
            'alpha_lasso':     lasso_pipe.named_steps['lassocv'].alpha_,
            'alpha_ridge':     ridge_pipe.named_steps['ridgecv'].alpha_
        })

# --- 5) SUMMARY TABLE ---
summary_lasso = pd.DataFrame(results_list).set_index(['target','horizon'])
print(summary_lasso)

def plot_comparison(forecasts, target, horizons):
    n = len(horizons)
    fig, axes = plt.subplots(n, 1, figsize=(10, 3*n), sharex=True)
    if n == 1:
        axes = [axes]
    for ax, h in zip(axes, horizons):
        pl, ac = forecasts[target]['lasso'][h]
        pr, _  = forecasts[target]['ridge'][h]

        # convert PeriodIndex to TimestampIndex for plotting
        time = ac.index.to_timestamp()

        ax.plot(time, ac.values,    'o-', label='Actual')
        ax.plot(time, pl.values,    'x--', label='Lasso')
        ax.plot(time, pr.values,    '^:',  label='Ridge')

        rmse_l = summary_lasso.loc[(target, h), 'rmse_lasso']
        rmse_r = summary_lasso.loc[(target, h), 'rmse_ridge']
        ax.set_title(f"{target} (h={h}): RMSE Lasso={rmse_l:.3f}, Ridge={rmse_r:.3f}")
        ax.legend(loc='best')
        ax.grid(True)
        ax.set_ylabel(target)

    axes[-1].set_xlabel('Date')
    plt.tight_layout()
    plt.show()

# --- 7) MAKE PLOTS ---
for t in targets:
    plot_comparison(forecast_store, t, horizons)

"""## Table to compare Lasso and Ridge to Factors"""

print(summary_factors)

print(summary_lasso)

import pandas as pd

# Assuming summary_factors and summary_lasso are already defined DataFrames

# --- Prepare summary_factors ---
# Reset index to manipulate easier
factors = summary_factors.reset_index()

# --- Prepare summary_lasso ---
# Split into excess return and volatility forecasts
lasso = summary_lasso.reset_index()
lasso_exret = lasso[lasso['target'].str.endswith('_exret')].copy()
lasso_vol = lasso[lasso['target'].str.startswith('VOL')].copy()

# Parse asset names
lasso_exret['asset'] = lasso_exret['target'].str.replace('_exret', '')
lasso_vol['asset'] = lasso_vol['target'].str.replace('VOL_', '')
lasso_vol['asset'] = lasso_vol['asset'].replace({'VOL': 'SPX'})  # Normalize SPX naming

# --- Merge excess return forecasts ---
exret_merged = pd.merge(
    factors[['asset', 'horizon', 'ret_factors', 'rmse_fac_ret', 'rmse_ar1_ret']],
    lasso_exret[['asset', 'horizon', 'rmse_lasso', 'rmse_ridge', 'n_nonzero_lasso', 'alpha_lasso', 'alpha_ridge']],
    on=['asset', 'horizon'],
    how='inner'
)
exret_merged = exret_merged.set_index(['asset', 'horizon'])

# --- Merge volatility forecasts ---
vol_merged = pd.merge(
    factors[['asset', 'horizon', 'vol_factors', 'rmse_fac_vol', 'rmse_ar1_vol']],
    lasso_vol[['asset', 'horizon', 'rmse_lasso', 'rmse_ridge', 'n_nonzero_lasso', 'alpha_lasso', 'alpha_ridge']],
    on=['asset', 'horizon'],
    how='inner'
)
vol_merged = vol_merged.set_index(['asset', 'horizon'])

# Drop the specified columns
cols_to_drop = ['ret_factors', 'vol_factors', 'n_nonzero_lasso', 'alpha_lasso', 'alpha_ridge']

# Drop only the columns that exist in each DataFrame
excess_ret_cleaned = exret_merged.drop(columns=[col for col in cols_to_drop if col in exret_merged.columns])
vol_cleaned = vol_merged.drop(columns=[col for col in cols_to_drop if col in vol_merged.columns])

# Resulting tables
print("Cleaned Excess Return Forecasts Table:")
print(excess_ret_cleaned)

print("\nCleaned Volatility Forecasts Table:")
print(vol_cleaned)

print(excess_ret_cleaned.to_latex(
    index=True,
    float_format="%.6f",
    caption="Forecast Accuracy for Excess Returns",
    label="tab:excess_return_forecasts",
    multicolumn=True,
    multirow=True
))

print(vol_cleaned.to_latex(
    index=True,
    float_format="%.6f",
    caption="Forecast Accuracy for Volatility",
    label="tab:volatility_forecasts",
    multicolumn=True,
    multirow=True
))

"""# Re-estimation with Shorter Vintage

We repeat the analysis excluding the volatile COVID 19 pandemic
"""

import pandas as pd
import numpy as np
# Remove the first -- second in data frame -- row (which held the tcodes)
# df = get_data("FE_projects/2025-03.csv",transform=True)
# df = get_data('/content/drive/MyDrive/FE_projects/2025-03.csv',transform=True)
df = get_data('2025-03.csv',transform=True)

# make 1980:1 the start to 2019:12
df=df.iloc[252:-62,:]
df

# Check for optimal amount of factors via BIC
optimal_components, bic_values = select_optimal_components(standardized_df, max_components=10)
print(f"Optimal number of components: {optimal_components}")

bic_values

standardized_df, stats = standardize_dataframe(df)
num_factors = 8
F, Lambda, X_complete = em_dynamic_factor_balanced_init(standardized_df, num_factors)

# removing the first transformation row significantly improve the graphs!
import matplotlib.pyplot as plt
plt.plot(F[:,0], label='factor 1')
plt.plot(F[:,1], label='factor 2')
plt.plot(F[:,2], label='factor 3')
plt.plot(F[:,3], label='factor 4')
plt.plot(F[:,4], label='factor 5')
plt.plot(F[:,5], label='factor 6')
plt.plot(F[:,6], label='factor 7')
plt.plot(F[:,7], label='factor 8')
# plt.plot(F[:,8], label='factor 9')
# plt.plot(F[:,9], label='factor 10')
plt.legend();

# Compute the cumulative R² for each series as factors are added.
R2_matrix = compute_R2_values(X_complete, F)

# Then compute the incremental R² (mR²) for each factor for each series and the average across series.
mR2_individual, mR2_average = compute_incremental_R2(R2_matrix)

series_names = df.columns.tolist()

# Optionally, create column labels for the factors
factor_labels = [f'Factor_{i+1}' for i in range(num_factors)]

# Create a DataFrame from the mR2_individual array with the desired indices and columns
mR2_df = pd.DataFrame(mR2_individual, index=series_names, columns=factor_labels)
mR2_df

mR2_df.sort_values(by='Factor_1', ascending=False).head(10)

print(mR2_average)
sum(mR2_average)

"""The factors explain more when using data starting the 1980s rather than 1960s

## Factor Prediction
"""

# We create our factors dataframe for the forecasting below
factors_df = pd.DataFrame(F, columns=[f"Factor_{i+1}" for i in range(8)])
factors_df.index = df.index
factors_df.index = factors_df.index.to_period('M')
factors_df

"""Change to forecasting using an ARMA(p,q) selected via BIC to see if we get better model performance"""

from statsmodels.tsa.arima.model import ARIMA
from sklearn.metrics import mean_squared_error

# 1) TRAIN/TEST SPLIT (80/20 by time)
n        = len(factors_df)
n_train  = int(0.8 * n)
train_df = factors_df.iloc[:n_train]
test_df  = factors_df.iloc[n_train:]

# 2) SELECT BEST ARMA(p,q) BY BIC, FORECAST & RMSE
max_p = 3
max_q = 3

arma_models = {}
rmse_arma   = {}
arma_params = {}

for col in factors_df.columns:
    y_tr = train_df[col].dropna()
    best_bic, best_order, best_mod = np.inf, None, None

    # grid search p=0..max_p, q=0..max_q
    for p in range(max_p+1):
        for q in range(max_q+1):
            try:
                mod = ARIMA(y_tr, order=(p,0,q)).fit(method_kwargs={"warn_convergence":False})
                if mod.bic < best_bic:
                    best_bic, best_order, best_mod = mod.bic, (p,0,q), mod
            except Exception:
                continue

    arma_models[col]   = best_mod
    arma_params[col]   = {"order":best_order, **best_mod.params.to_dict()}

    # one‐step‐ahead on test set:
    # supply forecast length = len(test_df)
    y_pred = best_mod.forecast(steps=len(test_df))
    y_true = test_df[col]
    rmse_arma[col] = np.sqrt(mean_squared_error(y_true, y_pred))

# 3) COEFFICIENTS AND RMSE TABLES
coef_df = (pd.DataFrame(arma_params)
            .T
            .rename(columns=lambda x: x if x!="order" else "arma_order"))
rmse_df = pd.Series(rmse_arma, name="ARMA_test_RMSE")

print("ARMA(p,q) Coefficients & Orders\n")
print(coef_df)
print("\nTest RMSEs\n")
print(rmse_df)

# 4) ONE‐STEP FORECASTS FROM 1980‐01 ONWARD
start      = "1980-01"
slice_df   = factors_df.loc[start:]
forecast_df = pd.DataFrame(index=slice_df.index)

for col, mod in arma_models.items():
    # merge train + slice so dynamic=False uses actual y(t−1) at each step
    full = pd.concat([train_df[col], slice_df[col]])
    preds_full = mod.predict(start=full.index[0], end=full.index[-1], dynamic=False)
    forecast_df[col] = preds_full.loc[slice_df.index]

# 5) UNIFIED DATAFRAME
forecast_df   = forecast_df.add_suffix("_ARMA")
unified_df    = pd.concat([slice_df, forecast_df], axis=1)
print("\nUnified forecasts (first 5 rows):\n")
print(unified_df.head())

"""## Stock Market Data"""

# 1) Define the tickers
SPX_TICKER  = "^GSPC"   # S&P 500 index
TBILL_TICKER = "^IRX"   # CBOE 13‑Week T‑Bill (^IRX gives the annualized % yield)
WMT_TICKER = "WMT"
AAPL_TICKER = "AAPL"
# 2) Download history
#    Adjust start/end as needed
data = yf.download(
    [SPX_TICKER, TBILL_TICKER, WMT_TICKER, AAPL_TICKER],
    start="1981-01-01",
    end="2025-03-31",
    progress=False
)

# 3) Keep only the Adj Close columns
df_stocks = data["Close"].rename(columns={
    SPX_TICKER: "SPX_Close",
    WMT_TICKER: "WMT_Close",
    AAPL_TICKER: "AAPL_Close",
    TBILL_TICKER: "Tbill_Yield"
})

# 4) Convert T‑bill from % to daily log‐yield
#    IRX is quoted as a percent annual rate, so:
df_stocks["Tbill_Yield"] = df_stocks["Tbill_Yield"] / 100            # → decimal annual rate
df_stocks["rf_daily"]    = np.log1p(df_stocks["Tbill_Yield"] / 252)   # assume 252 trading days

# 5) Compute daily SPX log‐return and excess‐return
df_stocks["spx_ret"]     = np.log(df_stocks["SPX_Close"]).diff()
df_stocks["spx_exret"]   = df_stocks["spx_ret"] - df_stocks["rf_daily"]
# same fore walmart WMT
df_stocks["wmt_ret"]     = np.log(df_stocks["WMT_Close"]).diff()
df_stocks["wmt_exret"]   = df_stocks["wmt_ret"] - df_stocks["rf_daily"]
# same for AAPL
df_stocks["aapl_ret"]     = np.log(df_stocks["AAPL_Close"]).diff()
df_stocks["aapl_exret"]   = df_stocks["aapl_ret"] - df_stocks["rf_daily"]

# 6) Long Sample mean of daily excess return
Rbar = df_stocks["spx_exret"].mean()
Rbar_WMT = df_stocks["wmt_exret"].mean()
Rbar_AAPL = df_stocks["aapl_exret"].mean()

# 7) Squared Deviations will be the variance
df_stocks["sq_dev"] = (df_stocks["spx_exret"] - Rbar)**2
df_stocks["sq_dev_WMT"]= (df_stocks["wmt_exret"] - Rbar_WMT)**2
df_stocks["sq_dev_AAPL"]= (df_stocks["aapl_exret"] - Rbar_AAPL)**2

# 8) We aggregate to Monthly volatility from daily
# Sum daily numbers, then take the square-root
monthly_vol = (
    df_stocks["sq_dev"]
      .resample("ME")    # monthly groups instead of quarterly
      .sum()            # Σ (R_sk – R̄_s)^2 for k in month m
      .pipe(np.sqrt)    # √[ Σ (…) ]
      .rename("VOL")
)
monthly_vol_wmt = (
    df_stocks["sq_dev_WMT"]
      .resample("ME")    # monthly groups instead of quarterly
      .sum()            # Σ (R_sk – R̄_s)^2 for k in month m
      .pipe(np.sqrt)    # √[ Σ (…) ]
      .rename("VOL")
)
monthly_vol_aapl = (
    df_stocks["sq_dev_AAPL"]
      .resample("ME")    # monthly groups instead of quarterly
      .sum()            # Σ (R_sk – R̄_s)^2 for k in month m
      .pipe(np.sqrt)
      .rename("VOL")
)

# 9) Monthly Panel
monthly = pd.DataFrame({
    "SPX_exret": df_stocks["spx_exret"].resample("ME").sum(),
    "WMT_exret": df_stocks["wmt_exret"].resample("ME").sum(),
    "AAPL_exret": df_stocks["aapl_exret"].resample("ME").sum(),
    "Tbill_Yield": df_stocks["Tbill_Yield"].resample("ME").mean(),
    "VOL": monthly_vol,
    "VOL_WMT": monthly_vol_wmt,
    "VOL_AAPL": monthly_vol_aapl
})

# remove day from date
monthly.index = monthly.index.to_period('M')
monthly

# we merged our dataframes for the regressions below
# Reset the index of the original DataFrame to align with the factors
df_merged = pd.concat([monthly, unified_df], axis=1)
df_merged = df_merged.dropna(subset=['Factor_1', 'SPX_exret'])
# drop the first row due to not having a forecast
df_merged = df_merged.iloc[1:]
print(df_merged)

"""## Regression

### Function code

### 3-factor model forecast
"""

import numpy as np
import pandas as pd
import statsmodels.api as sm
from statsmodels.tsa.arima.model import ARIMA

def forecast_analysis(
    df,
    ret_var,
    vol_var,
    factor_cols,
    h,
    ret_factors,
    vol_factors,
    max_ret_ar=3,
    max_ret_ma=3
):
    # 0) copy, sort, and rescale for numerical stability
    df2 = df.copy().sort_index()
    df2[ret_var] *= 100
    df2[vol_var] *= 100

    # 1) build h-step leads and one-lag return (for ARMA benchmark)
    df2[f"{ret_var}_lead"] = df2[ret_var].shift(-h)
    df2[f"{vol_var}_lead"] = df2[vol_var].shift(-h)
    df2["vol_t"]           = df2[vol_var]
    df2[f"{ret_var}_lag1"] = df2[ret_var].shift(1)

    # 2) drop missing, split train/test
    df_ret = df2[[f"{ret_var}_lead", f"{ret_var}_lag1"] + factor_cols].dropna()
    df_vol = df2[[f"{vol_var}_lead", "vol_t"] + factor_cols].dropna()

    split_ret = int(0.8 * len(df_ret))
    split_vol = int(0.8 * len(df_vol))

    train_ret, test_ret = df_ret.iloc[:split_ret], df_ret.iloc[split_ret:]
    train_vol, test_vol = df_vol.iloc[:split_vol], df_vol.iloc[split_vol:]

    # 3) Factor-augmented return forecast (no lagged returns)
    y_tr_ret = train_ret[f"{ret_var}_lead"]
    y_te_ret = test_ret[f"{ret_var}_lead"]

    X_tr_fac = sm.add_constant(train_ret[factor_cols[:ret_factors]])
    X_te_fac = sm.add_constant(test_ret[factor_cols[:ret_factors]])

    fac_mod   = sm.OLS(y_tr_ret, X_tr_fac).fit()
    y_hat_fac = fac_mod.predict(X_te_fac)
    rmse_fac  = np.sqrt(((y_te_ret - y_hat_fac)**2).mean())

    # 4) ARMA(p,q) benchmark for returns (select by BIC)
    best_bic_ret, best_arma_ret = np.inf, None
    for p in range(max_ret_ar+1):
        for q in range(max_ret_ma+1):
            try:
                m = ARIMA(
                    y_tr_ret,
                    order=(p,0,q),
                    enforce_stationarity=False,
                    enforce_invertibility=False
                ).fit()
                if m.bic < best_bic_ret:
                    best_bic_ret, best_arma_ret = m.bic, m
            except:
                continue

    y_hat_arma_ret = best_arma_ret.predict(
        start=test_ret.index[0],
        end=test_ret.index[-1]
    )
    rmse_arma_ret = np.sqrt(((y_te_ret - y_hat_arma_ret)**2).mean())

    # 5) Factor-augmented volatility forecast
    y_tr_vol = train_vol[f"{vol_var}_lead"]
    y_te_vol = test_vol[f"{vol_var}_lead"]

    X_tr_vf = sm.add_constant(train_vol[["vol_t"] + factor_cols[:vol_factors]])
    X_te_vf = sm.add_constant(test_vol[["vol_t"] + factor_cols[:vol_factors]])

    vfac_mod  = sm.OLS(y_tr_vol, X_tr_vf).fit()
    y_hat_vf  = vfac_mod.predict(X_te_vf)
    rmse_vf   = np.sqrt(((y_te_vol - y_hat_vf)**2).mean())

    # 6) ARMA(p,q) benchmark for volatility (select by BIC)
    best_bic_vol, best_arma_vol = np.inf, None
    for p in range(max_ret_ar+1):
        for q in range(max_ret_ma+1):
            try:
                m = ARIMA(
                    y_tr_vol,
                    order=(p,0,q),
                    enforce_stationarity=False,
                    enforce_invertibility=False
                ).fit()
                if m.bic < best_bic_vol:
                    best_bic_vol, best_arma_vol = m.bic, m
            except:
                continue

    y_hat_arma_vol = best_arma_vol.predict(
        start=test_vol.index[0],
        end=test_vol.index[-1]
    )
    rmse_arma_vol = np.sqrt(((y_te_vol - y_hat_arma_vol)**2).mean())

    return {
        "horizon":        h,
        "ret_factors":    ret_factors,
        "rmse_fac_ret":   rmse_fac,
        "rmse_arma_ret":  rmse_arma_ret,
        "vol_factors":    vol_factors,
        "rmse_fac_vol":   rmse_vf,
        "rmse_arma_vol":  rmse_arma_vol
    }

# ------------------------
# CONFIGURATION & RUN
manual_config = {h: {"ret_factors": 3, "vol_factors": 3} for h in [1,3,6,9,12,24]}
horizons      = [1,3,6,9,12,24]
assets        = [
    ("SPX_exret", "VOL"),
    ("WMT_exret","VOL_WMT"),
    ("AAPL_exret","VOL_AAPL")
]

# Raw factor names (omit any “_ARMA” columns)
factor_cols = [c for c in df_merged.columns
               if c.startswith("Factor_") and not c.endswith("_ARMA")]

all_results = []
for ret_var, vol_var in assets:
    for h in horizons:
        cfg = manual_config[h]
        res = forecast_analysis(
            df=            df_merged,
            ret_var=       ret_var,
            vol_var=       vol_var,
            factor_cols=   factor_cols,
            h=             h,
            ret_factors=   cfg["ret_factors"],
            vol_factors=   cfg["vol_factors"],
            max_ret_ar=    3,
            max_ret_ma=    3
        )
        res["asset"] = ret_var.split("_")[0]
        all_results.append(res)

summary_factors = pd.DataFrame(all_results).set_index(["asset","horizon"])
print(summary_factors)

"""### 8-Factor model"""

# ----------------------------------------------------------------
# YOUR MANUAL CONFIG: for each horizon, how many factors to use
manual_config = {
    1:  {"ret_factors": 8, "vol_factors": 8},
    3:  {"ret_factors": 8, "vol_factors": 8},
    6:  {"ret_factors": 8, "vol_factors": 8},
    9:  {"ret_factors": 8, "vol_factors": 8},
    12: {"ret_factors": 8, "vol_factors": 8},
    24: {"ret_factors": 8, "vol_factors": 8},
}

horizons = [1,3,6,9,12,24]
assets   = [
    ("SPX_exret","VOL"),
    ("WMT_exret","VOL_WMT"),
    ("AAPL_exret","VOL_AAPL")
]

all_results = []
for ret_var, vol_var in assets:
    for h in horizons:
        cfg = manual_config[h]
        res = forecast_analysis_manual(
            df=            df_merged,           # or your winsorized df
            ret_var=       ret_var,
            vol_var=       vol_var,
            factor_cols=   factor_pred_cols,
            h=             h,
            ret_factors=   cfg["ret_factors"],
            vol_factors=   cfg["vol_factors"],
        )
        res["asset"] = ret_var.split("_")[0]
        all_results.append(res)

# Build summary table
summary_factors = pd.DataFrame(all_results).set_index(["asset","horizon"])
print(summary_factors)